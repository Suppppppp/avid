{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# seed 0 Warm up + Batch norm gamma setting (layer 4 bottleneck index 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 10950\n",
      "Validation dataset size: 300\n",
      "['false', 'pneumonia']\n",
      "######### Validation Dataset #########\n",
      "false size: 200\n",
      "pneumonia size: 100\n",
      "layer4의 2번째-bottleneck의 bn1.weight\n",
      "layer4.2.bn1.weight의 gammm one setting 완료\n",
      "\n",
      "layer4의 2번째-bottleneck의 bn1.bias\n",
      "layer4.2.bn1.bias의 beta zero setting 완료\n",
      "\n",
      "layer4의 2번째-bottleneck의 bn2.weight\n",
      "layer4.2.bn2.weight의 gammm one setting 완료\n",
      "\n",
      "layer4의 2번째-bottleneck의 bn2.bias\n",
      "layer4.2.bn2.bias의 beta zero setting 완료\n",
      "\n",
      "layer4의 2번째-bottleneck의 bn3.weight\n",
      "layer4.2.bn3.weight의 gammm zero setting 완료\n",
      "\n",
      "layer4의 2번째-bottleneck의 bn3.bias\n",
      "layer4.2.bn3.bias의 beta zero setting 완료\n",
      "\n",
      "Epoch 0/19\n",
      "----------\n",
      "val Loss: 0.6586 Acc: 67.0000\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 99.5\n",
      "False Precision: 67.0\n",
      "False ACC: 67.0\n",
      "False F1 score: 80.08\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 2.0\n",
      "Pneumonia Precision: 66.67\n",
      "Pneumonia ACC: 67.0\n",
      "Pneumonia F1 score: 3.88\n",
      "\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "val Loss: 0.4682 Acc: 75.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 67.0\n",
      "False Precision: 94.37\n",
      "False ACC: 75.33\n",
      "False F1 score: 78.36\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 92.0\n",
      "Pneumonia Precision: 58.230000000000004\n",
      "Pneumonia ACC: 75.33\n",
      "Pneumonia F1 score: 71.32\n",
      "\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "val Loss: 0.3565 Acc: 83.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 79.0\n",
      "False Precision: 95.17999999999999\n",
      "False ACC: 83.33\n",
      "False F1 score: 86.34\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 92.0\n",
      "Pneumonia Precision: 68.66\n",
      "Pneumonia ACC: 83.33\n",
      "Pneumonia F1 score: 78.63\n",
      "\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "val Loss: 0.3005 Acc: 86.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 84.0\n",
      "False Precision: 94.92\n",
      "False ACC: 86.33\n",
      "False F1 score: 89.13\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 91.0\n",
      "Pneumonia Precision: 73.98\n",
      "Pneumonia ACC: 86.33\n",
      "Pneumonia F1 score: 81.61\n",
      "\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "val Loss: 0.3168 Acc: 85.0000\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 81.0\n",
      "False Precision: 95.86\n",
      "False ACC: 85.0\n",
      "False F1 score: 87.81\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 93.0\n",
      "Pneumonia Precision: 70.99\n",
      "Pneumonia ACC: 85.0\n",
      "Pneumonia F1 score: 80.52\n",
      "\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "val Loss: 0.2681 Acc: 89.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 88.0\n",
      "False Precision: 96.17\n",
      "False ACC: 89.67\n",
      "False F1 score: 91.9\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 93.0\n",
      "Pneumonia Precision: 79.49000000000001\n",
      "Pneumonia ACC: 89.67\n",
      "Pneumonia F1 score: 85.72\n",
      "\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "val Loss: 0.1893 Acc: 92.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 93.0\n",
      "False Precision: 95.38\n",
      "False ACC: 92.33\n",
      "False F1 score: 94.17\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 91.0\n",
      "Pneumonia Precision: 86.67\n",
      "Pneumonia ACC: 92.33\n",
      "Pneumonia F1 score: 88.78\n",
      "\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "val Loss: 0.2677 Acc: 89.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 87.0\n",
      "False Precision: 96.67\n",
      "False ACC: 89.33\n",
      "False F1 score: 91.58\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 78.33\n",
      "Pneumonia ACC: 89.33\n",
      "Pneumonia F1 score: 85.45\n",
      "\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "val Loss: 0.1492 Acc: 95.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 95.0\n",
      "False Precision: 97.94\n",
      "False ACC: 95.33\n",
      "False F1 score: 96.45\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 96.0\n",
      "Pneumonia Precision: 90.57\n",
      "Pneumonia ACC: 95.33\n",
      "Pneumonia F1 score: 93.21\n",
      "\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "val Loss: 0.2180 Acc: 91.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 89.5\n",
      "False Precision: 97.28\n",
      "False ACC: 91.33\n",
      "False F1 score: 93.23\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 95.0\n",
      "Pneumonia Precision: 81.89999999999999\n",
      "Pneumonia ACC: 91.33\n",
      "Pneumonia F1 score: 87.96\n",
      "\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "val Loss: 0.2077 Acc: 92.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 91.5\n",
      "False Precision: 97.34\n",
      "False ACC: 92.67\n",
      "False F1 score: 94.33\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 95.0\n",
      "Pneumonia Precision: 84.82\n",
      "Pneumonia ACC: 92.67\n",
      "Pneumonia F1 score: 89.62\n",
      "\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "val Loss: 0.2301 Acc: 89.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 87.0\n",
      "False Precision: 97.21\n",
      "False ACC: 89.67\n",
      "False F1 score: 91.82\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 95.0\n",
      "Pneumonia Precision: 78.51\n",
      "Pneumonia ACC: 89.67\n",
      "Pneumonia F1 score: 85.97\n",
      "\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "val Loss: 0.2449 Acc: 89.0000\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 86.0\n",
      "False Precision: 97.18\n",
      "False ACC: 89.0\n",
      "False F1 score: 91.25\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 95.0\n",
      "Pneumonia Precision: 77.24\n",
      "Pneumonia ACC: 89.0\n",
      "Pneumonia F1 score: 85.2\n",
      "\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "val Loss: 0.2285 Acc: 90.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 88.5\n",
      "False Precision: 97.25\n",
      "False ACC: 90.67\n",
      "False F1 score: 92.67\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 95.0\n",
      "Pneumonia Precision: 80.51\n",
      "Pneumonia ACC: 90.67\n",
      "Pneumonia F1 score: 87.16\n",
      "\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "val Loss: 0.2586 Acc: 89.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 86.5\n",
      "False Precision: 97.19\n",
      "False ACC: 89.33\n",
      "False F1 score: 91.53\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 95.0\n",
      "Pneumonia Precision: 77.86999999999999\n",
      "Pneumonia ACC: 89.33\n",
      "Pneumonia F1 score: 85.59\n",
      "\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "val Loss: 0.1814 Acc: 93.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 93.0\n",
      "False Precision: 96.88\n",
      "False ACC: 93.33\n",
      "False F1 score: 94.9\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 87.03999999999999\n",
      "Pneumonia ACC: 93.33\n",
      "Pneumonia F1 score: 90.39\n",
      "\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "val Loss: 0.2337 Acc: 91.0000\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 89.0\n",
      "False Precision: 97.27\n",
      "False ACC: 91.0\n",
      "False F1 score: 92.95\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 95.0\n",
      "Pneumonia Precision: 81.2\n",
      "Pneumonia ACC: 91.0\n",
      "Pneumonia F1 score: 87.56\n",
      "\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "val Loss: 0.1994 Acc: 92.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 91.0\n",
      "False Precision: 97.33000000000001\n",
      "False ACC: 92.33\n",
      "False F1 score: 94.06\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 95.0\n",
      "Pneumonia Precision: 84.07\n",
      "Pneumonia ACC: 92.33\n",
      "Pneumonia F1 score: 89.2\n",
      "\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "val Loss: 0.2013 Acc: 92.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 91.5\n",
      "False Precision: 97.34\n",
      "False ACC: 92.67\n",
      "False F1 score: 94.33\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 95.0\n",
      "Pneumonia Precision: 84.82\n",
      "Pneumonia ACC: 92.67\n",
      "Pneumonia F1 score: 89.62\n",
      "\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "val Loss: 0.2051 Acc: 92.0000\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 90.5\n",
      "False Precision: 97.31\n",
      "False ACC: 92.0\n",
      "False F1 score: 93.78\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 95.0\n",
      "Pneumonia Precision: 83.33\n",
      "Pneumonia ACC: 92.0\n",
      "Pneumonia F1 score: 88.78\n",
      "\n",
      "\n",
      "Training complete in 35m 13s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nif epoch < 6:\\n    # freeze backbone layers\\n    for param in net.parameters():\\n        count +=1\\n        if count < 4: #freezing first 3 layers\\n            param.requires_grad = False    \\n        else:\\n            for param in net.parameters():\\n                aram.requires_grad = True\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Author: Sasank Chilamkurthy\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "from openpyxl import Workbook\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "# from pytorch_cosine_annealing_warmup_master import cosine_annearing_with_warmup\n",
    "import random\n",
    "\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "#torch.set_deterministic(True)\n",
    "random_seed = 0\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.3)),\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.15,0.1)),\n",
    "        transforms.RandomAffine(degrees=(-10,10)),\n",
    "        transforms.Resize(280),\n",
    "        transforms.CenterCrop(224),\n",
    "        #transforms.Resize(size=(224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        transforms.Normalize([0.493, 0.493, 0.493], [0.246, 0.246, 0.246])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        #transforms.Resize(size=(224,224)),\n",
    "        transforms.Resize(280),\n",
    "        transforms.CenterCrop(224),\n",
    "        #transforms.Resize(size=(224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        transforms.Normalize([0.493, 0.493, 0.493], [0.246, 0.246, 0.246])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = '/home/aiffel/Hackathon_covid_19/data_2'\n",
    "#data_dir = 'Crop_CXR/binary_covid'\n",
    "batch_size = 16\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "val_class_names = image_datasets['val'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Training dataset size: \" + str(dataset_sizes['train']))\n",
    "print(\"Validation dataset size: \" +str(dataset_sizes['val']))\n",
    "print(val_class_names)\n",
    "\n",
    "\n",
    "val_dir = '/home/aiffel/Hackathon_covid_19/data_2/val/'\n",
    "false_data_dir = val_dir + 'false'\n",
    "pneumonia_data_dir = val_dir + 'pneumonia'\n",
    "\n",
    "print(\"######### Validation Dataset #########\")\n",
    "val_false_num = len(os.listdir(false_data_dir))\n",
    "val_pneumonia_num = len(os.listdir(pneumonia_data_dir))\n",
    "print(\"false size: \" + str(val_false_num))\n",
    "print(\"pneumonia size: \" + str(val_pneumonia_num))\n",
    "\n",
    "wb = Workbook()      # 워크북을 생성한다.\n",
    "ws = wb.active       # 워크 시트를 얻는다.\n",
    "    \n",
    "ws['A1'] = 'ResNet50'\n",
    "ws['B1'] = 'Val ACC'\n",
    "\n",
    "ws['D1'] = 'False ACC'\n",
    "ws['E1'] = 'False Recall'\n",
    "ws['F1'] = 'False Precision'\n",
    "ws['G1'] = 'False F1'\n",
    "\n",
    "ws['I1'] = 'Penumonia ACC'\n",
    "ws['J1'] = 'Penumonia Recall'\n",
    "ws['K1'] = 'Penumonia Precision'\n",
    "ws['L1'] = 'Penumonia F1'\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    best_false_acc = 0.0\n",
    "    best_false_f1 = 0.0\n",
    "    best_pneumonia_acc = 0.0\n",
    "    best_pneumonia_f1 = 0.0\n",
    "\n",
    "    best_false_acc_epoch = 0\n",
    "    best_false_f1_epoch = 0\n",
    "    best_pneumonia_acc_epoch = 0\n",
    "    best_pneumonia_f1_epoch = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        val_false_TP = 0.0\n",
    "        val_pneumonia_TP = 0.0\n",
    "        val_false_FN = 0.0\n",
    "        val_pneumonia_FN = 0.0\n",
    "        val_false_TN = 0.0\n",
    "        val_pneumonia_TN = 0.0\n",
    "        val_false_FP = 0.0\n",
    "        val_pneumonia_FP = 0.0\n",
    "\n",
    "        \n",
    "        \n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        A = 'A'+str(epoch+2)\n",
    "        ws[A] = 'Epoch' + str(epoch+1)\n",
    "    \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    #outputs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    # Append batch prediction results\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                a = preds.size()\n",
    "                b = a[0]\n",
    "                \n",
    "                if phase == 'val':\n",
    "                    for i in range(b):\n",
    "                        if preds[i].item() == labels.data[i].item():\n",
    "                            #Normal-index:0, Pneumonia-index:1\n",
    "                            if preds.data[i].item() == 0: \n",
    "                                val_false_TP += 1 #Normal 관점에서는 normal를 정확히 분류하는 것이 TP\n",
    "                                val_pneumonia_TN += 1 #Pneumonia 관점에서는 normal를 정확히 분류하는 것이 TN\n",
    "                            elif preds.data[i].item() == 1: \n",
    "                                val_pneumonia_TP += 1 #Pneumonia 관점에서는 Pneumonia를 정확히 분류하는 것이 TP\n",
    "                                val_false_TN += 1 #Normal 관점에서는 Pneumonia를 정확히 분류하는 것이 TN\n",
    "\n",
    "                        if preds[i].item() != labels.data[i].item():\n",
    "                            if preds.data[i].item() == 0:\n",
    "                                val_false_FP += 1 #Normal 관점에서 normal라고 분류했지만 실제로는 pneumonia인 경우는 FP\n",
    "                                val_pneumonia_FN += 1 #Pneumonia 관점에서 normal라고 분류했지만 실제로는 pneumonia인 경우는 FN\n",
    "                            elif preds.data[i].item() == 1:\n",
    "                                val_pneumonia_FP += 1 #Normal 관점에서 pneumonia라고 분류했지만 실제로는 normal인 경우는 FP\n",
    "                                val_false_FN += 1 #Pneumonia 관점에서 pneumonia라고 분류했지만 실제로는 normal인 경우는 FN\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                \n",
    "            \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "           \n",
    "            if phase == 'val':\n",
    "                B = 'B'+str(epoch+2)\n",
    "                ws[B] = '{:.4f}'.format(epoch_acc*100)\n",
    "\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, (epoch_acc*100)))    \n",
    "\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "\n",
    "        #recall, precision -> https://en.wikipedia.org/wiki/Precision_and_recall\n",
    "        #recall = TP/(TP+FN)\n",
    "        #precision = TP/(TP+FP)\n",
    "        #ACC = (TP+TN)/(TP+TN+FP+FN)\n",
    "        false_recall = round(val_false_TP/(val_false_TP + val_false_FN),4)*100\n",
    "        pneumonia_recall = round(val_pneumonia_TP/(val_pneumonia_TP + val_pneumonia_FN),4)*100\n",
    "        false_precision = round(val_false_TP/(val_false_TP + val_false_FP),4)*100\n",
    "        pneumonia_precision = round(val_pneumonia_TP/(val_pneumonia_TP + val_pneumonia_FP),4)*100\n",
    "        false_acc = round((val_false_TP + val_false_TN)/(val_false_TP + val_false_FP +val_false_TN + val_false_FN),4)*100\n",
    "        pneumonia_acc = round((val_pneumonia_TP + val_pneumonia_TN)/(val_pneumonia_TP + val_pneumonia_FP +val_pneumonia_TN + val_pneumonia_FN),4)*100\n",
    "        #F1 score -> https://en.wikipedia.org/wiki/F-score\n",
    "        #F1 score = 2/((1/recall)+(1/precision)) = 2((precision*recall)/(precision+recall)) = tp/(tp+((1/2)(fp+fn)))\n",
    "        false_f1_score = round(2*(false_precision*false_recall)/(false_precision+false_recall),2)\n",
    "        pneumonia_f1_score = round(2*(pneumonia_precision*pneumonia_recall)/(pneumonia_precision+pneumonia_recall),2)\n",
    "\n",
    "        #total_data = batch size --> covid_total_dataset = false_total_dataset\n",
    "        false_total_dataset = int(val_false_TP + val_false_FP +val_false_TN + val_false_FN)\n",
    "        pneumonia_total_dataset = int(val_pneumonia_TP + val_pneumonia_FP +val_pneumonia_TN + val_pneumonia_FN)\n",
    "        \n",
    "      \n",
    "        D = 'D'+str(epoch+2)\n",
    "        E = 'E'+str(epoch+2)\n",
    "        F = 'F'+str(epoch+2)\n",
    "        G = 'G'+str(epoch+2)\n",
    "        \n",
    "        I = 'I'+str(epoch+2)\n",
    "        J = 'J'+str(epoch+2)\n",
    "        K = 'K'+str(epoch+2)\n",
    "        L = 'L'+str(epoch+2)\n",
    "\n",
    "        ws[D] = false_acc\n",
    "        ws[E] = false_recall\n",
    "        ws[F] = false_precision\n",
    "        ws[G] = false_f1_score\n",
    "        \n",
    "        ws[I] = pneumonia_acc\n",
    "        ws[J] = pneumonia_recall\n",
    "        ws[K] = pneumonia_precision\n",
    "        ws[L] = pneumonia_f1_score\n",
    "\n",
    "\n",
    "        print()\n",
    "\n",
    "        print('데이터셋A: ' + str(false_total_dataset))\n",
    "        print('False Recall: ' + str(false_recall))        \n",
    "        print('False Precision: ' + str(false_precision))\n",
    "        print('False ACC: ' + str(false_acc))\n",
    "        print('False F1 score: ' + str(false_f1_score))\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        print('데이터셋B: ' + str(pneumonia_total_dataset))\n",
    "        print('Pneumonia Recall: ' + str(pneumonia_recall))\n",
    "        print('Pneumonia Precision: ' + str(pneumonia_precision))\n",
    "        print('Pneumonia ACC: ' + str(pneumonia_acc))\n",
    "        print('Pneumonia F1 score: ' + str(pneumonia_f1_score))\n",
    "        \n",
    "  \n",
    "        if phase == 'val' and false_acc > best_false_acc:\n",
    "            best_false_acc = false_acc\n",
    "            best_false_acc_epoch = epoch\n",
    "\n",
    "        if phase == 'val' and pneumonia_acc > best_pneumonia_acc:\n",
    "            best_pneumonia_acc = pneumonia_acc\n",
    "            best_pneumonia_acc_epoch = epoch\n",
    "            \n",
    "\n",
    "        if phase == 'val' and false_f1_score > best_false_f1:\n",
    "            best_false_f1 = false_f1_score\n",
    "            best_false_f1_epoch = epoch\n",
    "            \n",
    "        if phase == 'val' and pneumonia_f1_score > best_pneumonia_f1:\n",
    "            best_pneumonia_f1 = pneumonia_f1_score\n",
    "            best_pneumonia_f1_epoch = epoch\n",
    "\n",
    "        print()\n",
    "        print()\n",
    "\n",
    "    \n",
    "    ws['N1'] = 'Best False ACC'\n",
    "    ws['O1'] = 'epoch'\n",
    "    ws['N2'] = round(best_false_acc,2)\n",
    "    ws['O2'] = best_false_acc_epoch+1\n",
    "        \n",
    "    ws['N4'] = 'Best False F1'\n",
    "    ws['O4'] = 'epoch'\n",
    "    ws['N5'] = round(best_false_f1,2)\n",
    "    ws['O5'] = best_false_f1_epoch+1\n",
    "        \n",
    "    ws['N7'] = 'Best Pneumonia ACC'\n",
    "    ws['O7'] = 'epoch'\n",
    "    ws['N8'] = round(best_pneumonia_acc,2)\n",
    "    ws['O8'] = best_pneumonia_acc_epoch+1\n",
    "        \n",
    "    ws['N10'] = 'Best Pneumonia F1'\n",
    "    ws['O10'] = 'epoch'\n",
    "    ws['N11'] = round(best_pneumonia_f1,2)\n",
    "    ws['O11'] = best_pneumonia_f1_epoch+1\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    #print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "    # load best model weights\n",
    "    #model.load_state_dict(best_covid_wts)\n",
    "    wb.save('output_excel/현수님세팅_Pneumonia_vs_Fasle(train5475_P 기준세팅)_Balanced(val)_seed_0_BatchNorm_layer_4_bottleneck_2.xlsx') # 엑셀로 저장한다. \n",
    "    #torch.save(model.state_dict(), 'covid_binary.pt')\n",
    "    return model\n",
    "\n",
    "\n",
    "model_ft = models.resnet50(pretrained=True)\n",
    "\n",
    "###BatchNorm Gamma setting###\n",
    "\n",
    "\n",
    "# seed 0,1,2\n",
    "\n",
    "# count =0\n",
    "# bottleneck_count = 0\n",
    "# layer_index=1\n",
    "# layer_name = 'layer'+str(layer_index)\n",
    "# bottleneck_index = 0\n",
    "\n",
    "\n",
    "\n",
    "# count =0\n",
    "# bottleneck_count = 0\n",
    "# layer_index=4\n",
    "# layer_name = 'layer'+str(layer_index)\n",
    "# bottleneck_index = 0\n",
    "\n",
    "\n",
    "count =0\n",
    "bottleneck_count = 0\n",
    "layer_index=4\n",
    "layer_name = 'layer'+str(layer_index)\n",
    "bottleneck_index = 2\n",
    "\n",
    "\n",
    "\n",
    "for name, layer in model_ft.named_children():\n",
    "    if bottleneck_count > 0:\n",
    "        bottleneck_index = 0\n",
    "    if name == layer_name:\n",
    "        bn_index = 1\n",
    "        for name, param in model_ft.named_parameters():\n",
    "            if name == layer_name + '.' + str(bottleneck_index) + '.' + 'bn1.weight':\n",
    "                print(str(layer_name + \"의 \" + str(bottleneck_index)+ \"번째-bottleneck의 \" + 'bn1.weight'))\n",
    "                torch.nn.init.ones_(param)\n",
    "                print(name + '의 gammm one setting 완료')\n",
    "                print()\n",
    "                \n",
    "            elif name == layer_name + '.' + str(bottleneck_index) + '.' + 'bn2.weight':\n",
    "                print(str(layer_name + \"의 \" + str(bottleneck_index)+ \"번째-bottleneck의 \" + 'bn2.weight'))\n",
    "                torch.nn.init.ones_(param)\n",
    "                print(name + '의 gammm one setting 완료')\n",
    "                print()\n",
    "\n",
    "            elif name == layer_name + '.' + str(bottleneck_index) + '.' + 'bn3.weight':\n",
    "                print(str(layer_name + \"의 \" + str(bottleneck_index)+ \"번째-bottleneck의 \" + 'bn3.weight'))\n",
    "                torch.nn.init.zeros_(param)\n",
    "                print(name + '의 gammm zero setting 완료')\n",
    "                print()\n",
    "\n",
    "            elif name == layer_name + '.' + str(bottleneck_index) + '.' + 'bn' + str(bn_index) + '.bias':\n",
    "                print(str(layer_name + \"의 \" + str(bottleneck_index)+ \"번째-bottleneck의 \" + 'bn' + str(bn_index) + '.bias'))\n",
    "                torch.nn.init.zeros_(param)\n",
    "                bn_index = bn_index + 1\n",
    "                if name == layer_name + '.' + str(bottleneck_index) + '.' + 'bn3.bias':\n",
    "                    bottleneck_index = bottleneck_index + 1\n",
    "                    bn_index = 1\n",
    "                print(name + '의 beta zero setting 완료')\n",
    "                print()\n",
    "\n",
    "        bottleneck_count = bottleneck_count + 1\n",
    "        layer_index = layer_index+ 1\n",
    "        layer_name = 'layer'+str(layer_index)     \n",
    "\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)\n",
    "#exp_lr_scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max, eta_min=0, last_epoch=-1, verbose=False)\n",
    "exp_lr_scheduler = GradualWarmupScheduler(optimizer_ft, multiplier=1, total_epoch=5, after_scheduler=exp_lr_scheduler)\n",
    "#exp_lr_scheduler = cosine_annearing_with_warmup.CosineAnnealingWarmUpRestarts(optimizer_ft, T_0=30, T_mult=1, eta_max=0.001, T_up=20)\n",
    "\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=20)\n",
    "\n",
    "# freeze backbone layers\n",
    "'''\n",
    "count = 0\n",
    "for child_name, param in model_ft.named_children():\n",
    "    for param_name, param_param in model_ft.named_parameters():\n",
    "        if child_name == 'layer4': \n",
    "            param_param.requires_grad = True\n",
    "        else:\n",
    "            param_param.requires_grad = False\n",
    "'''\n",
    "\n",
    "\n",
    "#특정 conv layer 이후 초기화\n",
    "'''\n",
    "children_index = 4\n",
    "children_name = 'layer'+str(children_index)\n",
    "bottleneck_index = 2\n",
    "for name, layer in model_ft.named_children():\n",
    "    if name == children_name:\n",
    "        conv_index = 1\n",
    "        for name, param in model_ft.named_parameters():\n",
    "            if name == children_name + \".\" + str(bottleneck_index) + '.' + 'conv' + str(conv_index) + '.weight':\n",
    "                print(children_name + \"의 \"+ str(bottleneck_index)+ \"번째-bottleneck의 \" + 'conv' +str(conv_index) + '.weight')\n",
    "                torch.nn.init.xavier_uniform_(param)\n",
    "                print(name + '의 conv filter initilization setting 완료')\n",
    "                print()\n",
    "                conv_index = conv_index + 1\n",
    "                if name == 'layer3.' + str(bottleneck_index) + '.' + 'conv3.weight':\n",
    "                    bottleneck_index = bottleneck_index + 1\n",
    "                    conv_index = 1\n",
    "                elif name == 'layer4.' + str(bottleneck_index) + '.' + 'conv3.weight':\n",
    "                    bottleneck_index = bottleneck_index + 1\n",
    "                    conv_index = 1\n",
    "        children_index = children_index + 1\n",
    "        children_name = 'layer'+str(children_index)\n",
    "        bottleneck_index = 0\n",
    "'''        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#increase fine-tune layer per epoch\n",
    "'''\n",
    "if epoch < 6:\n",
    "    # freeze backbone layers\n",
    "    for param in net.parameters():\n",
    "        count +=1\n",
    "        if count < 4: #freezing first 3 layers\n",
    "            param.requires_grad = False    \n",
    "        else:\n",
    "            for param in net.parameters():\n",
    "                aram.requires_grad = True\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# seed 1 Warm up + Batch norm gamma setting (layer 4 bottleneck index 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 10950\n",
      "Validation dataset size: 300\n",
      "['false', 'pneumonia']\n",
      "######### Validation Dataset #########\n",
      "false size: 200\n",
      "pneumonia size: 100\n",
      "layer4의 2번째-bottleneck의 bn1.weight\n",
      "layer4.2.bn1.weight의 gammm one setting 완료\n",
      "\n",
      "layer4의 2번째-bottleneck의 bn1.bias\n",
      "layer4.2.bn1.bias의 beta zero setting 완료\n",
      "\n",
      "layer4의 2번째-bottleneck의 bn2.weight\n",
      "layer4.2.bn2.weight의 gammm one setting 완료\n",
      "\n",
      "layer4의 2번째-bottleneck의 bn2.bias\n",
      "layer4.2.bn2.bias의 beta zero setting 완료\n",
      "\n",
      "layer4의 2번째-bottleneck의 bn3.weight\n",
      "layer4.2.bn3.weight의 gammm zero setting 완료\n",
      "\n",
      "layer4의 2번째-bottleneck의 bn3.bias\n",
      "layer4.2.bn3.bias의 beta zero setting 완료\n",
      "\n",
      "Epoch 0/19\n",
      "----------\n",
      "val Loss: 0.7194 Acc: 35.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 6.5\n",
      "False Precision: 68.42\n",
      "False ACC: 35.67\n",
      "False F1 score: 11.87\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 33.45\n",
      "Pneumonia ACC: 35.67\n",
      "Pneumonia F1 score: 49.34\n",
      "\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "val Loss: 0.4808 Acc: 76.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 69.0\n",
      "False Precision: 94.52000000000001\n",
      "False ACC: 76.67\n",
      "False F1 score: 79.77\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 92.0\n",
      "Pneumonia Precision: 59.74\n",
      "Pneumonia ACC: 76.67\n",
      "Pneumonia F1 score: 72.44\n",
      "\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "val Loss: 0.2852 Acc: 88.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 88.5\n",
      "False Precision: 94.15\n",
      "False ACC: 88.67\n",
      "False F1 score: 91.24\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 89.0\n",
      "Pneumonia Precision: 79.46\n",
      "Pneumonia ACC: 88.67\n",
      "Pneumonia F1 score: 83.96\n",
      "\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "val Loss: 0.2091 Acc: 92.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 94.0\n",
      "False Precision: 94.47\n",
      "False ACC: 92.33\n",
      "False F1 score: 94.23\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 89.0\n",
      "Pneumonia Precision: 88.12\n",
      "Pneumonia ACC: 92.33\n",
      "Pneumonia F1 score: 88.56\n",
      "\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "val Loss: 0.2109 Acc: 91.0000\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 91.5\n",
      "False Precision: 94.82000000000001\n",
      "False ACC: 91.0\n",
      "False F1 score: 93.13\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 90.0\n",
      "Pneumonia Precision: 84.11\n",
      "Pneumonia ACC: 91.0\n",
      "Pneumonia F1 score: 86.96\n",
      "\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "val Loss: 0.3201 Acc: 85.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 80.5\n",
      "False Precision: 96.99\n",
      "False ACC: 85.33\n",
      "False F1 score: 87.98\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 95.0\n",
      "Pneumonia Precision: 70.89999999999999\n",
      "Pneumonia ACC: 85.33\n",
      "Pneumonia F1 score: 81.2\n",
      "\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "val Loss: 0.1806 Acc: 93.0000\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 92.5\n",
      "False Precision: 96.86\n",
      "False ACC: 93.0\n",
      "False F1 score: 94.63\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 86.24000000000001\n",
      "Pneumonia ACC: 93.0\n",
      "Pneumonia F1 score: 89.95\n",
      "\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "val Loss: 0.2606 Acc: 90.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 89.0\n",
      "False Precision: 96.22\n",
      "False ACC: 90.33\n",
      "False F1 score: 92.47\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 93.0\n",
      "Pneumonia Precision: 80.87\n",
      "Pneumonia ACC: 90.33\n",
      "Pneumonia F1 score: 86.51\n",
      "\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "val Loss: 0.1763 Acc: 92.0000\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 91.0\n",
      "False Precision: 96.81\n",
      "False ACC: 92.0\n",
      "False F1 score: 93.82\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 83.93\n",
      "Pneumonia ACC: 92.0\n",
      "Pneumonia F1 score: 88.68\n",
      "\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "val Loss: 0.2157 Acc: 91.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 90.0\n",
      "False Precision: 96.77\n",
      "False ACC: 91.33\n",
      "False F1 score: 93.26\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 82.46\n",
      "Pneumonia ACC: 91.33\n",
      "Pneumonia F1 score: 87.85\n",
      "\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "val Loss: 0.1871 Acc: 92.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 91.5\n",
      "False Precision: 97.34\n",
      "False ACC: 92.67\n",
      "False F1 score: 94.33\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 95.0\n",
      "Pneumonia Precision: 84.82\n",
      "Pneumonia ACC: 92.67\n",
      "Pneumonia F1 score: 89.62\n",
      "\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "val Loss: 0.1848 Acc: 93.0000\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 92.0\n",
      "False Precision: 97.35000000000001\n",
      "False ACC: 93.0\n",
      "False F1 score: 94.6\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 95.0\n",
      "Pneumonia Precision: 85.59\n",
      "Pneumonia ACC: 93.0\n",
      "Pneumonia F1 score: 90.05\n",
      "\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "val Loss: 0.2036 Acc: 91.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 90.0\n",
      "False Precision: 96.77\n",
      "False ACC: 91.33\n",
      "False F1 score: 93.26\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 82.46\n",
      "Pneumonia ACC: 91.33\n",
      "Pneumonia F1 score: 87.85\n",
      "\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "val Loss: 0.1988 Acc: 92.0000\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 90.5\n",
      "False Precision: 97.31\n",
      "False ACC: 92.0\n",
      "False F1 score: 93.78\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 95.0\n",
      "Pneumonia Precision: 83.33\n",
      "Pneumonia ACC: 92.0\n",
      "Pneumonia F1 score: 88.78\n",
      "\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "val Loss: 0.2233 Acc: 91.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 89.5\n",
      "False Precision: 97.28\n",
      "False ACC: 91.33\n",
      "False F1 score: 93.23\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 95.0\n",
      "Pneumonia Precision: 81.89999999999999\n",
      "Pneumonia ACC: 91.33\n",
      "Pneumonia F1 score: 87.96\n",
      "\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "val Loss: 0.1934 Acc: 92.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 91.5\n",
      "False Precision: 97.34\n",
      "False ACC: 92.67\n",
      "False F1 score: 94.33\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 95.0\n",
      "Pneumonia Precision: 84.82\n",
      "Pneumonia ACC: 92.67\n",
      "Pneumonia F1 score: 89.62\n",
      "\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "val Loss: 0.2022 Acc: 92.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 91.5\n",
      "False Precision: 97.34\n",
      "False ACC: 92.67\n",
      "False F1 score: 94.33\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 95.0\n",
      "Pneumonia Precision: 84.82\n",
      "Pneumonia ACC: 92.67\n",
      "Pneumonia F1 score: 89.62\n",
      "\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "val Loss: 0.2009 Acc: 92.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 92.0\n",
      "False Precision: 96.84\n",
      "False ACC: 92.67\n",
      "False F1 score: 94.36\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 85.45\n",
      "Pneumonia ACC: 92.67\n",
      "Pneumonia F1 score: 89.52\n",
      "\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "val Loss: 0.1805 Acc: 93.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 93.0\n",
      "False Precision: 96.88\n",
      "False ACC: 93.33\n",
      "False F1 score: 94.9\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 87.03999999999999\n",
      "Pneumonia ACC: 93.33\n",
      "Pneumonia F1 score: 90.39\n",
      "\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "val Loss: 0.1942 Acc: 92.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 91.5\n",
      "False Precision: 96.83\n",
      "False ACC: 92.33\n",
      "False F1 score: 94.09\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 84.68\n",
      "Pneumonia ACC: 92.33\n",
      "Pneumonia F1 score: 89.1\n",
      "\n",
      "\n",
      "Training complete in 36m 6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nif epoch < 6:\\n    # freeze backbone layers\\n    for param in net.parameters():\\n        count +=1\\n        if count < 4: #freezing first 3 layers\\n            param.requires_grad = False    \\n        else:\\n            for param in net.parameters():\\n                aram.requires_grad = True\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Author: Sasank Chilamkurthy\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "from openpyxl import Workbook\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "# from pytorch_cosine_annealing_warmup_master import cosine_annearing_with_warmup\n",
    "import random\n",
    "\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "#torch.set_deterministic(True)\n",
    "random_seed = 1\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.3)),\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.15,0.1)),\n",
    "        transforms.RandomAffine(degrees=(-10,10)),\n",
    "        transforms.Resize(280),\n",
    "        transforms.CenterCrop(224),\n",
    "        #transforms.Resize(size=(224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        transforms.Normalize([0.493, 0.493, 0.493], [0.246, 0.246, 0.246])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        #transforms.Resize(size=(224,224)),\n",
    "        transforms.Resize(280),\n",
    "        transforms.CenterCrop(224),\n",
    "        #transforms.Resize(size=(224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        transforms.Normalize([0.493, 0.493, 0.493], [0.246, 0.246, 0.246])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = '/home/aiffel/Hackathon_covid_19/data_2'\n",
    "#data_dir = 'Crop_CXR/binary_covid'\n",
    "batch_size = 16\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "val_class_names = image_datasets['val'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Training dataset size: \" + str(dataset_sizes['train']))\n",
    "print(\"Validation dataset size: \" +str(dataset_sizes['val']))\n",
    "print(val_class_names)\n",
    "\n",
    "\n",
    "val_dir = '/home/aiffel/Hackathon_covid_19/data_2/val/'\n",
    "false_data_dir = val_dir + 'false'\n",
    "pneumonia_data_dir = val_dir + 'pneumonia'\n",
    "\n",
    "print(\"######### Validation Dataset #########\")\n",
    "val_false_num = len(os.listdir(false_data_dir))\n",
    "val_pneumonia_num = len(os.listdir(pneumonia_data_dir))\n",
    "print(\"false size: \" + str(val_false_num))\n",
    "print(\"pneumonia size: \" + str(val_pneumonia_num))\n",
    "\n",
    "wb = Workbook()      # 워크북을 생성한다.\n",
    "ws = wb.active       # 워크 시트를 얻는다.\n",
    "    \n",
    "ws['A1'] = 'ResNet50'\n",
    "ws['B1'] = 'Val ACC'\n",
    "\n",
    "ws['D1'] = 'False ACC'\n",
    "ws['E1'] = 'False Recall'\n",
    "ws['F1'] = 'False Precision'\n",
    "ws['G1'] = 'False F1'\n",
    "\n",
    "ws['I1'] = 'Penumonia ACC'\n",
    "ws['J1'] = 'Penumonia Recall'\n",
    "ws['K1'] = 'Penumonia Precision'\n",
    "ws['L1'] = 'Penumonia F1'\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    best_false_acc = 0.0\n",
    "    best_false_f1 = 0.0\n",
    "    best_pneumonia_acc = 0.0\n",
    "    best_pneumonia_f1 = 0.0\n",
    "\n",
    "    best_false_acc_epoch = 0\n",
    "    best_false_f1_epoch = 0\n",
    "    best_pneumonia_acc_epoch = 0\n",
    "    best_pneumonia_f1_epoch = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        val_false_TP = 0.0\n",
    "        val_pneumonia_TP = 0.0\n",
    "        val_false_FN = 0.0\n",
    "        val_pneumonia_FN = 0.0\n",
    "        val_false_TN = 0.0\n",
    "        val_pneumonia_TN = 0.0\n",
    "        val_false_FP = 0.0\n",
    "        val_pneumonia_FP = 0.0\n",
    "\n",
    "        \n",
    "        \n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        A = 'A'+str(epoch+2)\n",
    "        ws[A] = 'Epoch' + str(epoch+1)\n",
    "    \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    #outputs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    # Append batch prediction results\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                a = preds.size()\n",
    "                b = a[0]\n",
    "                \n",
    "                if phase == 'val':\n",
    "                    for i in range(b):\n",
    "                        if preds[i].item() == labels.data[i].item():\n",
    "                            #Normal-index:0, Pneumonia-index:1\n",
    "                            if preds.data[i].item() == 0: \n",
    "                                val_false_TP += 1 #Normal 관점에서는 normal를 정확히 분류하는 것이 TP\n",
    "                                val_pneumonia_TN += 1 #Pneumonia 관점에서는 normal를 정확히 분류하는 것이 TN\n",
    "                            elif preds.data[i].item() == 1: \n",
    "                                val_pneumonia_TP += 1 #Pneumonia 관점에서는 Pneumonia를 정확히 분류하는 것이 TP\n",
    "                                val_false_TN += 1 #Normal 관점에서는 Pneumonia를 정확히 분류하는 것이 TN\n",
    "\n",
    "                        if preds[i].item() != labels.data[i].item():\n",
    "                            if preds.data[i].item() == 0:\n",
    "                                val_false_FP += 1 #Normal 관점에서 normal라고 분류했지만 실제로는 pneumonia인 경우는 FP\n",
    "                                val_pneumonia_FN += 1 #Pneumonia 관점에서 normal라고 분류했지만 실제로는 pneumonia인 경우는 FN\n",
    "                            elif preds.data[i].item() == 1:\n",
    "                                val_pneumonia_FP += 1 #Normal 관점에서 pneumonia라고 분류했지만 실제로는 normal인 경우는 FP\n",
    "                                val_false_FN += 1 #Pneumonia 관점에서 pneumonia라고 분류했지만 실제로는 normal인 경우는 FN\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                \n",
    "            \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "           \n",
    "            if phase == 'val':\n",
    "                B = 'B'+str(epoch+2)\n",
    "                ws[B] = '{:.4f}'.format(epoch_acc*100)\n",
    "\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, (epoch_acc*100)))    \n",
    "\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "\n",
    "        #recall, precision -> https://en.wikipedia.org/wiki/Precision_and_recall\n",
    "        #recall = TP/(TP+FN)\n",
    "        #precision = TP/(TP+FP)\n",
    "        #ACC = (TP+TN)/(TP+TN+FP+FN)\n",
    "        false_recall = round(val_false_TP/(val_false_TP + val_false_FN),4)*100\n",
    "        pneumonia_recall = round(val_pneumonia_TP/(val_pneumonia_TP + val_pneumonia_FN),4)*100\n",
    "        false_precision = round(val_false_TP/(val_false_TP + val_false_FP),4)*100\n",
    "        pneumonia_precision = round(val_pneumonia_TP/(val_pneumonia_TP + val_pneumonia_FP),4)*100\n",
    "        false_acc = round((val_false_TP + val_false_TN)/(val_false_TP + val_false_FP +val_false_TN + val_false_FN),4)*100\n",
    "        pneumonia_acc = round((val_pneumonia_TP + val_pneumonia_TN)/(val_pneumonia_TP + val_pneumonia_FP +val_pneumonia_TN + val_pneumonia_FN),4)*100\n",
    "        #F1 score -> https://en.wikipedia.org/wiki/F-score\n",
    "        #F1 score = 2/((1/recall)+(1/precision)) = 2((precision*recall)/(precision+recall)) = tp/(tp+((1/2)(fp+fn)))\n",
    "        false_f1_score = round(2*(false_precision*false_recall)/(false_precision+false_recall),2)\n",
    "        pneumonia_f1_score = round(2*(pneumonia_precision*pneumonia_recall)/(pneumonia_precision+pneumonia_recall),2)\n",
    "\n",
    "        #total_data = batch size --> covid_total_dataset = false_total_dataset\n",
    "        false_total_dataset = int(val_false_TP + val_false_FP +val_false_TN + val_false_FN)\n",
    "        pneumonia_total_dataset = int(val_pneumonia_TP + val_pneumonia_FP +val_pneumonia_TN + val_pneumonia_FN)\n",
    "        \n",
    "      \n",
    "        D = 'D'+str(epoch+2)\n",
    "        E = 'E'+str(epoch+2)\n",
    "        F = 'F'+str(epoch+2)\n",
    "        G = 'G'+str(epoch+2)\n",
    "        \n",
    "        I = 'I'+str(epoch+2)\n",
    "        J = 'J'+str(epoch+2)\n",
    "        K = 'K'+str(epoch+2)\n",
    "        L = 'L'+str(epoch+2)\n",
    "\n",
    "        ws[D] = false_acc\n",
    "        ws[E] = false_recall\n",
    "        ws[F] = false_precision\n",
    "        ws[G] = false_f1_score\n",
    "        \n",
    "        ws[I] = pneumonia_acc\n",
    "        ws[J] = pneumonia_recall\n",
    "        ws[K] = pneumonia_precision\n",
    "        ws[L] = pneumonia_f1_score\n",
    "\n",
    "\n",
    "        print()\n",
    "\n",
    "        print('데이터셋A: ' + str(false_total_dataset))\n",
    "        print('False Recall: ' + str(false_recall))        \n",
    "        print('False Precision: ' + str(false_precision))\n",
    "        print('False ACC: ' + str(false_acc))\n",
    "        print('False F1 score: ' + str(false_f1_score))\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        print('데이터셋B: ' + str(pneumonia_total_dataset))\n",
    "        print('Pneumonia Recall: ' + str(pneumonia_recall))\n",
    "        print('Pneumonia Precision: ' + str(pneumonia_precision))\n",
    "        print('Pneumonia ACC: ' + str(pneumonia_acc))\n",
    "        print('Pneumonia F1 score: ' + str(pneumonia_f1_score))\n",
    "        \n",
    "  \n",
    "        if phase == 'val' and false_acc > best_false_acc:\n",
    "            best_false_acc = false_acc\n",
    "            best_false_acc_epoch = epoch\n",
    "\n",
    "        if phase == 'val' and pneumonia_acc > best_pneumonia_acc:\n",
    "            best_pneumonia_acc = pneumonia_acc\n",
    "            best_pneumonia_acc_epoch = epoch\n",
    "            \n",
    "\n",
    "        if phase == 'val' and false_f1_score > best_false_f1:\n",
    "            best_false_f1 = false_f1_score\n",
    "            best_false_f1_epoch = epoch\n",
    "            \n",
    "        if phase == 'val' and pneumonia_f1_score > best_pneumonia_f1:\n",
    "            best_pneumonia_f1 = pneumonia_f1_score\n",
    "            best_pneumonia_f1_epoch = epoch\n",
    "\n",
    "        print()\n",
    "        print()\n",
    "\n",
    "    \n",
    "    ws['N1'] = 'Best False ACC'\n",
    "    ws['O1'] = 'epoch'\n",
    "    ws['N2'] = round(best_false_acc,2)\n",
    "    ws['O2'] = best_false_acc_epoch+1\n",
    "        \n",
    "    ws['N4'] = 'Best False F1'\n",
    "    ws['O4'] = 'epoch'\n",
    "    ws['N5'] = round(best_false_f1,2)\n",
    "    ws['O5'] = best_false_f1_epoch+1\n",
    "        \n",
    "    ws['N7'] = 'Best Pneumonia ACC'\n",
    "    ws['O7'] = 'epoch'\n",
    "    ws['N8'] = round(best_pneumonia_acc,2)\n",
    "    ws['O8'] = best_pneumonia_acc_epoch+1\n",
    "        \n",
    "    ws['N10'] = 'Best Pneumonia F1'\n",
    "    ws['O10'] = 'epoch'\n",
    "    ws['N11'] = round(best_pneumonia_f1,2)\n",
    "    ws['O11'] = best_pneumonia_f1_epoch+1\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    #print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "    # load best model weights\n",
    "    #model.load_state_dict(best_covid_wts)\n",
    "    wb.save('output_excel/현수님세팅_Pneumonia_vs_Fasle(train5475_P 기준세팅)_Balanced(val)_seed_1_BatchNorm_layer_4_bottleneck_2.xlsx') # 엑셀로 저장한다. \n",
    "    #torch.save(model.state_dict(), 'covid_binary.pt')\n",
    "    return model\n",
    "\n",
    "\n",
    "model_ft = models.resnet50(pretrained=True)\n",
    "\n",
    "###BatchNorm Gamma setting###\n",
    "\n",
    "\n",
    "# seed 0,1,2\n",
    "\n",
    "# count =0\n",
    "# bottleneck_count = 0\n",
    "# layer_index=1\n",
    "# layer_name = 'layer'+str(layer_index)\n",
    "# bottleneck_index = 0\n",
    "\n",
    "\n",
    "\n",
    "# count =0\n",
    "# bottleneck_count = 0\n",
    "# layer_index=4\n",
    "# layer_name = 'layer'+str(layer_index)\n",
    "# bottleneck_index = 0\n",
    "\n",
    "\n",
    "count =0\n",
    "bottleneck_count = 0\n",
    "layer_index=4\n",
    "layer_name = 'layer'+str(layer_index)\n",
    "bottleneck_index = 2\n",
    "\n",
    "\n",
    "\n",
    "for name, layer in model_ft.named_children():\n",
    "    if bottleneck_count > 0:\n",
    "        bottleneck_index = 0\n",
    "    if name == layer_name:\n",
    "        bn_index = 1\n",
    "        for name, param in model_ft.named_parameters():\n",
    "            if name == layer_name + '.' + str(bottleneck_index) + '.' + 'bn1.weight':\n",
    "                print(str(layer_name + \"의 \" + str(bottleneck_index)+ \"번째-bottleneck의 \" + 'bn1.weight'))\n",
    "                torch.nn.init.ones_(param)\n",
    "                print(name + '의 gammm one setting 완료')\n",
    "                print()\n",
    "                \n",
    "            elif name == layer_name + '.' + str(bottleneck_index) + '.' + 'bn2.weight':\n",
    "                print(str(layer_name + \"의 \" + str(bottleneck_index)+ \"번째-bottleneck의 \" + 'bn2.weight'))\n",
    "                torch.nn.init.ones_(param)\n",
    "                print(name + '의 gammm one setting 완료')\n",
    "                print()\n",
    "\n",
    "            elif name == layer_name + '.' + str(bottleneck_index) + '.' + 'bn3.weight':\n",
    "                print(str(layer_name + \"의 \" + str(bottleneck_index)+ \"번째-bottleneck의 \" + 'bn3.weight'))\n",
    "                torch.nn.init.zeros_(param)\n",
    "                print(name + '의 gammm zero setting 완료')\n",
    "                print()\n",
    "\n",
    "            elif name == layer_name + '.' + str(bottleneck_index) + '.' + 'bn' + str(bn_index) + '.bias':\n",
    "                print(str(layer_name + \"의 \" + str(bottleneck_index)+ \"번째-bottleneck의 \" + 'bn' + str(bn_index) + '.bias'))\n",
    "                torch.nn.init.zeros_(param)\n",
    "                bn_index = bn_index + 1\n",
    "                if name == layer_name + '.' + str(bottleneck_index) + '.' + 'bn3.bias':\n",
    "                    bottleneck_index = bottleneck_index + 1\n",
    "                    bn_index = 1\n",
    "                print(name + '의 beta zero setting 완료')\n",
    "                print()\n",
    "\n",
    "        bottleneck_count = bottleneck_count + 1\n",
    "        layer_index = layer_index+ 1\n",
    "        layer_name = 'layer'+str(layer_index)     \n",
    "\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)\n",
    "#exp_lr_scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max, eta_min=0, last_epoch=-1, verbose=False)\n",
    "exp_lr_scheduler = GradualWarmupScheduler(optimizer_ft, multiplier=1, total_epoch=5, after_scheduler=exp_lr_scheduler)\n",
    "#exp_lr_scheduler = cosine_annearing_with_warmup.CosineAnnealingWarmUpRestarts(optimizer_ft, T_0=30, T_mult=1, eta_max=0.001, T_up=20)\n",
    "\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=20)\n",
    "\n",
    "# freeze backbone layers\n",
    "'''\n",
    "count = 0\n",
    "for child_name, param in model_ft.named_children():\n",
    "    for param_name, param_param in model_ft.named_parameters():\n",
    "        if child_name == 'layer4': \n",
    "            param_param.requires_grad = True\n",
    "        else:\n",
    "            param_param.requires_grad = False\n",
    "'''\n",
    "\n",
    "\n",
    "#특정 conv layer 이후 초기화\n",
    "'''\n",
    "children_index = 4\n",
    "children_name = 'layer'+str(children_index)\n",
    "bottleneck_index = 2\n",
    "for name, layer in model_ft.named_children():\n",
    "    if name == children_name:\n",
    "        conv_index = 1\n",
    "        for name, param in model_ft.named_parameters():\n",
    "            if name == children_name + \".\" + str(bottleneck_index) + '.' + 'conv' + str(conv_index) + '.weight':\n",
    "                print(children_name + \"의 \"+ str(bottleneck_index)+ \"번째-bottleneck의 \" + 'conv' +str(conv_index) + '.weight')\n",
    "                torch.nn.init.xavier_uniform_(param)\n",
    "                print(name + '의 conv filter initilization setting 완료')\n",
    "                print()\n",
    "                conv_index = conv_index + 1\n",
    "                if name == 'layer3.' + str(bottleneck_index) + '.' + 'conv3.weight':\n",
    "                    bottleneck_index = bottleneck_index + 1\n",
    "                    conv_index = 1\n",
    "                elif name == 'layer4.' + str(bottleneck_index) + '.' + 'conv3.weight':\n",
    "                    bottleneck_index = bottleneck_index + 1\n",
    "                    conv_index = 1\n",
    "        children_index = children_index + 1\n",
    "        children_name = 'layer'+str(children_index)\n",
    "        bottleneck_index = 0\n",
    "'''        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#increase fine-tune layer per epoch\n",
    "'''\n",
    "if epoch < 6:\n",
    "    # freeze backbone layers\n",
    "    for param in net.parameters():\n",
    "        count +=1\n",
    "        if count < 4: #freezing first 3 layers\n",
    "            param.requires_grad = False    \n",
    "        else:\n",
    "            for param in net.parameters():\n",
    "                aram.requires_grad = True\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# seed 2  Warm up + Batch norm gamma setting (layer 4 bottleneck index 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 10950\n",
      "Validation dataset size: 300\n",
      "['false', 'pneumonia']\n",
      "######### Validation Dataset #########\n",
      "false size: 200\n",
      "pneumonia size: 100\n",
      "layer4의 2번째-bottleneck의 bn1.weight\n",
      "layer4.2.bn1.weight의 gammm one setting 완료\n",
      "\n",
      "layer4의 2번째-bottleneck의 bn1.bias\n",
      "layer4.2.bn1.bias의 beta zero setting 완료\n",
      "\n",
      "layer4의 2번째-bottleneck의 bn2.weight\n",
      "layer4.2.bn2.weight의 gammm one setting 완료\n",
      "\n",
      "layer4의 2번째-bottleneck의 bn2.bias\n",
      "layer4.2.bn2.bias의 beta zero setting 완료\n",
      "\n",
      "layer4의 2번째-bottleneck의 bn3.weight\n",
      "layer4.2.bn3.weight의 gammm zero setting 완료\n",
      "\n",
      "layer4의 2번째-bottleneck의 bn3.bias\n",
      "layer4.2.bn3.bias의 beta zero setting 완료\n",
      "\n",
      "Epoch 0/19\n",
      "----------\n",
      "val Loss: 0.7225 Acc: 29.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 19.0\n",
      "False Precision: 43.68\n",
      "False ACC: 29.67\n",
      "False F1 score: 26.48\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 51.0\n",
      "Pneumonia Precision: 23.94\n",
      "Pneumonia ACC: 29.67\n",
      "Pneumonia F1 score: 32.58\n",
      "\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "val Loss: 0.4928 Acc: 75.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 68.5\n",
      "False Precision: 93.2\n",
      "False ACC: 75.67\n",
      "False F1 score: 78.96\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 90.0\n",
      "Pneumonia Precision: 58.81999999999999\n",
      "Pneumonia ACC: 75.67\n",
      "Pneumonia F1 score: 71.14\n",
      "\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "val Loss: 0.2955 Acc: 87.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 87.0\n",
      "False Precision: 93.55\n",
      "False ACC: 87.33\n",
      "False F1 score: 90.16\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 88.0\n",
      "Pneumonia Precision: 77.19\n",
      "Pneumonia ACC: 87.33\n",
      "Pneumonia F1 score: 82.24\n",
      "\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "val Loss: 0.2145 Acc: 91.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 91.5\n",
      "False Precision: 95.81\n",
      "False ACC: 91.67\n",
      "False F1 score: 93.61\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 92.0\n",
      "Pneumonia Precision: 84.39999999999999\n",
      "Pneumonia ACC: 91.67\n",
      "Pneumonia F1 score: 88.04\n",
      "\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "val Loss: 0.4246 Acc: 80.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 74.5\n",
      "False Precision: 95.50999999999999\n",
      "False ACC: 80.67\n",
      "False F1 score: 83.71\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 93.0\n",
      "Pneumonia Precision: 64.58\n",
      "Pneumonia ACC: 80.67\n",
      "Pneumonia F1 score: 76.23\n",
      "\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "val Loss: 0.2318 Acc: 89.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 88.0\n",
      "False Precision: 95.65\n",
      "False ACC: 89.33\n",
      "False F1 score: 91.67\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 92.0\n",
      "Pneumonia Precision: 79.31\n",
      "Pneumonia ACC: 89.33\n",
      "Pneumonia F1 score: 85.18\n",
      "\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "val Loss: 0.1839 Acc: 93.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 93.0\n",
      "False Precision: 97.38\n",
      "False ACC: 93.67\n",
      "False F1 score: 95.14\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 95.0\n",
      "Pneumonia Precision: 87.16000000000001\n",
      "Pneumonia ACC: 93.67\n",
      "Pneumonia F1 score: 90.91\n",
      "\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "val Loss: 0.2856 Acc: 88.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 84.5\n",
      "False Precision: 97.69\n",
      "False ACC: 88.33\n",
      "False F1 score: 90.62\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 96.0\n",
      "Pneumonia Precision: 75.59\n",
      "Pneumonia ACC: 88.33\n",
      "Pneumonia F1 score: 84.58\n",
      "\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "val Loss: 0.2944 Acc: 88.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 85.5\n",
      "False Precision: 97.16\n",
      "False ACC: 88.67\n",
      "False F1 score: 90.96\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 95.0\n",
      "Pneumonia Precision: 76.61\n",
      "Pneumonia ACC: 88.67\n",
      "Pneumonia F1 score: 84.82\n",
      "\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "val Loss: 0.2462 Acc: 91.0000\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 89.0\n",
      "False Precision: 97.27\n",
      "False ACC: 91.0\n",
      "False F1 score: 92.95\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 95.0\n",
      "Pneumonia Precision: 81.2\n",
      "Pneumonia ACC: 91.0\n",
      "Pneumonia F1 score: 87.56\n",
      "\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "val Loss: 0.2117 Acc: 91.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 90.5\n",
      "False Precision: 96.78999999999999\n",
      "False ACC: 91.67\n",
      "False F1 score: 93.54\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 83.19\n",
      "Pneumonia ACC: 91.67\n",
      "Pneumonia F1 score: 88.27\n",
      "\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "val Loss: 0.2176 Acc: 91.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 90.0\n",
      "False Precision: 96.77\n",
      "False ACC: 91.33\n",
      "False F1 score: 93.26\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 82.46\n",
      "Pneumonia ACC: 91.33\n",
      "Pneumonia F1 score: 87.85\n",
      "\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "val Loss: 0.2214 Acc: 91.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 90.5\n",
      "False Precision: 96.78999999999999\n",
      "False ACC: 91.67\n",
      "False F1 score: 93.54\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 83.19\n",
      "Pneumonia ACC: 91.67\n",
      "Pneumonia F1 score: 88.27\n",
      "\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "val Loss: 0.1882 Acc: 93.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 93.0\n",
      "False Precision: 96.88\n",
      "False ACC: 93.33\n",
      "False F1 score: 94.9\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 87.03999999999999\n",
      "Pneumonia ACC: 93.33\n",
      "Pneumonia F1 score: 90.39\n",
      "\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "val Loss: 0.2505 Acc: 90.0000\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 88.0\n",
      "False Precision: 96.7\n",
      "False ACC: 90.0\n",
      "False F1 score: 92.15\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 79.66\n",
      "Pneumonia ACC: 90.0\n",
      "Pneumonia F1 score: 86.24\n",
      "\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "val Loss: 0.2520 Acc: 90.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 88.5\n",
      "False Precision: 96.72\n",
      "False ACC: 90.33\n",
      "False F1 score: 92.43\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 80.34\n",
      "Pneumonia ACC: 90.33\n",
      "Pneumonia F1 score: 86.63\n",
      "\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "val Loss: 0.2409 Acc: 91.0000\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 89.5\n",
      "False Precision: 96.76\n",
      "False ACC: 91.0\n",
      "False F1 score: 92.99\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 81.74\n",
      "Pneumonia ACC: 91.0\n",
      "Pneumonia F1 score: 87.44\n",
      "\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "val Loss: 0.2229 Acc: 91.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 90.0\n",
      "False Precision: 96.77\n",
      "False ACC: 91.33\n",
      "False F1 score: 93.26\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 82.46\n",
      "Pneumonia ACC: 91.33\n",
      "Pneumonia F1 score: 87.85\n",
      "\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "val Loss: 0.2176 Acc: 91.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 90.5\n",
      "False Precision: 96.78999999999999\n",
      "False ACC: 91.67\n",
      "False F1 score: 93.54\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 83.19\n",
      "Pneumonia ACC: 91.67\n",
      "Pneumonia F1 score: 88.27\n",
      "\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "val Loss: 0.2110 Acc: 91.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 90.5\n",
      "False Precision: 96.78999999999999\n",
      "False ACC: 91.67\n",
      "False F1 score: 93.54\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 83.19\n",
      "Pneumonia ACC: 91.67\n",
      "Pneumonia F1 score: 88.27\n",
      "\n",
      "\n",
      "Training complete in 39m 31s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nif epoch < 6:\\n    # freeze backbone layers\\n    for param in net.parameters():\\n        count +=1\\n        if count < 4: #freezing first 3 layers\\n            param.requires_grad = False    \\n        else:\\n            for param in net.parameters():\\n                aram.requires_grad = True\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Author: Sasank Chilamkurthy\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "from openpyxl import Workbook\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "# from pytorch_cosine_annealing_warmup_master import cosine_annearing_with_warmup\n",
    "import random\n",
    "\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "#torch.set_deterministic(True)\n",
    "random_seed = 2\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.3)),\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.15,0.1)),\n",
    "        transforms.RandomAffine(degrees=(-10,10)),\n",
    "        transforms.Resize(280),\n",
    "        transforms.CenterCrop(224),\n",
    "        #transforms.Resize(size=(224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        transforms.Normalize([0.493, 0.493, 0.493], [0.246, 0.246, 0.246])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        #transforms.Resize(size=(224,224)),\n",
    "        transforms.Resize(280),\n",
    "        transforms.CenterCrop(224),\n",
    "        #transforms.Resize(size=(224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        transforms.Normalize([0.493, 0.493, 0.493], [0.246, 0.246, 0.246])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = '/home/aiffel/Hackathon_covid_19/data_2'\n",
    "#data_dir = 'Crop_CXR/binary_covid'\n",
    "batch_size = 16\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "val_class_names = image_datasets['val'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Training dataset size: \" + str(dataset_sizes['train']))\n",
    "print(\"Validation dataset size: \" +str(dataset_sizes['val']))\n",
    "print(val_class_names)\n",
    "\n",
    "\n",
    "val_dir = '/home/aiffel/Hackathon_covid_19/data_2/val/'\n",
    "false_data_dir = val_dir + 'false'\n",
    "pneumonia_data_dir = val_dir + 'pneumonia'\n",
    "\n",
    "print(\"######### Validation Dataset #########\")\n",
    "val_false_num = len(os.listdir(false_data_dir))\n",
    "val_pneumonia_num = len(os.listdir(pneumonia_data_dir))\n",
    "print(\"false size: \" + str(val_false_num))\n",
    "print(\"pneumonia size: \" + str(val_pneumonia_num))\n",
    "\n",
    "wb = Workbook()      # 워크북을 생성한다.\n",
    "ws = wb.active       # 워크 시트를 얻는다.\n",
    "    \n",
    "ws['A1'] = 'ResNet50'\n",
    "ws['B1'] = 'Val ACC'\n",
    "\n",
    "ws['D1'] = 'False ACC'\n",
    "ws['E1'] = 'False Recall'\n",
    "ws['F1'] = 'False Precision'\n",
    "ws['G1'] = 'False F1'\n",
    "\n",
    "ws['I1'] = 'Penumonia ACC'\n",
    "ws['J1'] = 'Penumonia Recall'\n",
    "ws['K1'] = 'Penumonia Precision'\n",
    "ws['L1'] = 'Penumonia F1'\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    best_false_acc = 0.0\n",
    "    best_false_f1 = 0.0\n",
    "    best_pneumonia_acc = 0.0\n",
    "    best_pneumonia_f1 = 0.0\n",
    "\n",
    "    best_false_acc_epoch = 0\n",
    "    best_false_f1_epoch = 0\n",
    "    best_pneumonia_acc_epoch = 0\n",
    "    best_pneumonia_f1_epoch = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        val_false_TP = 0.0\n",
    "        val_pneumonia_TP = 0.0\n",
    "        val_false_FN = 0.0\n",
    "        val_pneumonia_FN = 0.0\n",
    "        val_false_TN = 0.0\n",
    "        val_pneumonia_TN = 0.0\n",
    "        val_false_FP = 0.0\n",
    "        val_pneumonia_FP = 0.0\n",
    "\n",
    "        \n",
    "        \n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        A = 'A'+str(epoch+2)\n",
    "        ws[A] = 'Epoch' + str(epoch+1)\n",
    "    \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    #outputs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    # Append batch prediction results\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                a = preds.size()\n",
    "                b = a[0]\n",
    "                \n",
    "                if phase == 'val':\n",
    "                    for i in range(b):\n",
    "                        if preds[i].item() == labels.data[i].item():\n",
    "                            #Normal-index:0, Pneumonia-index:1\n",
    "                            if preds.data[i].item() == 0: \n",
    "                                val_false_TP += 1 #Normal 관점에서는 normal를 정확히 분류하는 것이 TP\n",
    "                                val_pneumonia_TN += 1 #Pneumonia 관점에서는 normal를 정확히 분류하는 것이 TN\n",
    "                            elif preds.data[i].item() == 1: \n",
    "                                val_pneumonia_TP += 1 #Pneumonia 관점에서는 Pneumonia를 정확히 분류하는 것이 TP\n",
    "                                val_false_TN += 1 #Normal 관점에서는 Pneumonia를 정확히 분류하는 것이 TN\n",
    "\n",
    "                        if preds[i].item() != labels.data[i].item():\n",
    "                            if preds.data[i].item() == 0:\n",
    "                                val_false_FP += 1 #Normal 관점에서 normal라고 분류했지만 실제로는 pneumonia인 경우는 FP\n",
    "                                val_pneumonia_FN += 1 #Pneumonia 관점에서 normal라고 분류했지만 실제로는 pneumonia인 경우는 FN\n",
    "                            elif preds.data[i].item() == 1:\n",
    "                                val_pneumonia_FP += 1 #Normal 관점에서 pneumonia라고 분류했지만 실제로는 normal인 경우는 FP\n",
    "                                val_false_FN += 1 #Pneumonia 관점에서 pneumonia라고 분류했지만 실제로는 normal인 경우는 FN\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                \n",
    "            \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "           \n",
    "            if phase == 'val':\n",
    "                B = 'B'+str(epoch+2)\n",
    "                ws[B] = '{:.4f}'.format(epoch_acc*100)\n",
    "\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, (epoch_acc*100)))    \n",
    "\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "\n",
    "        #recall, precision -> https://en.wikipedia.org/wiki/Precision_and_recall\n",
    "        #recall = TP/(TP+FN)\n",
    "        #precision = TP/(TP+FP)\n",
    "        #ACC = (TP+TN)/(TP+TN+FP+FN)\n",
    "        false_recall = round(val_false_TP/(val_false_TP + val_false_FN),4)*100\n",
    "        pneumonia_recall = round(val_pneumonia_TP/(val_pneumonia_TP + val_pneumonia_FN),4)*100\n",
    "        false_precision = round(val_false_TP/(val_false_TP + val_false_FP),4)*100\n",
    "        pneumonia_precision = round(val_pneumonia_TP/(val_pneumonia_TP + val_pneumonia_FP),4)*100\n",
    "        false_acc = round((val_false_TP + val_false_TN)/(val_false_TP + val_false_FP +val_false_TN + val_false_FN),4)*100\n",
    "        pneumonia_acc = round((val_pneumonia_TP + val_pneumonia_TN)/(val_pneumonia_TP + val_pneumonia_FP +val_pneumonia_TN + val_pneumonia_FN),4)*100\n",
    "        #F1 score -> https://en.wikipedia.org/wiki/F-score\n",
    "        #F1 score = 2/((1/recall)+(1/precision)) = 2((precision*recall)/(precision+recall)) = tp/(tp+((1/2)(fp+fn)))\n",
    "        false_f1_score = round(2*(false_precision*false_recall)/(false_precision+false_recall),2)\n",
    "        pneumonia_f1_score = round(2*(pneumonia_precision*pneumonia_recall)/(pneumonia_precision+pneumonia_recall),2)\n",
    "\n",
    "        #total_data = batch size --> covid_total_dataset = false_total_dataset\n",
    "        false_total_dataset = int(val_false_TP + val_false_FP +val_false_TN + val_false_FN)\n",
    "        pneumonia_total_dataset = int(val_pneumonia_TP + val_pneumonia_FP +val_pneumonia_TN + val_pneumonia_FN)\n",
    "        \n",
    "      \n",
    "        D = 'D'+str(epoch+2)\n",
    "        E = 'E'+str(epoch+2)\n",
    "        F = 'F'+str(epoch+2)\n",
    "        G = 'G'+str(epoch+2)\n",
    "        \n",
    "        I = 'I'+str(epoch+2)\n",
    "        J = 'J'+str(epoch+2)\n",
    "        K = 'K'+str(epoch+2)\n",
    "        L = 'L'+str(epoch+2)\n",
    "\n",
    "        ws[D] = false_acc\n",
    "        ws[E] = false_recall\n",
    "        ws[F] = false_precision\n",
    "        ws[G] = false_f1_score\n",
    "        \n",
    "        ws[I] = pneumonia_acc\n",
    "        ws[J] = pneumonia_recall\n",
    "        ws[K] = pneumonia_precision\n",
    "        ws[L] = pneumonia_f1_score\n",
    "\n",
    "\n",
    "        print()\n",
    "\n",
    "        print('데이터셋A: ' + str(false_total_dataset))\n",
    "        print('False Recall: ' + str(false_recall))        \n",
    "        print('False Precision: ' + str(false_precision))\n",
    "        print('False ACC: ' + str(false_acc))\n",
    "        print('False F1 score: ' + str(false_f1_score))\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        print('데이터셋B: ' + str(pneumonia_total_dataset))\n",
    "        print('Pneumonia Recall: ' + str(pneumonia_recall))\n",
    "        print('Pneumonia Precision: ' + str(pneumonia_precision))\n",
    "        print('Pneumonia ACC: ' + str(pneumonia_acc))\n",
    "        print('Pneumonia F1 score: ' + str(pneumonia_f1_score))\n",
    "        \n",
    "  \n",
    "        if phase == 'val' and false_acc > best_false_acc:\n",
    "            best_false_acc = false_acc\n",
    "            best_false_acc_epoch = epoch\n",
    "\n",
    "        if phase == 'val' and pneumonia_acc > best_pneumonia_acc:\n",
    "            best_pneumonia_acc = pneumonia_acc\n",
    "            best_pneumonia_acc_epoch = epoch\n",
    "            \n",
    "\n",
    "        if phase == 'val' and false_f1_score > best_false_f1:\n",
    "            best_false_f1 = false_f1_score\n",
    "            best_false_f1_epoch = epoch\n",
    "            \n",
    "        if phase == 'val' and pneumonia_f1_score > best_pneumonia_f1:\n",
    "            best_pneumonia_f1 = pneumonia_f1_score\n",
    "            best_pneumonia_f1_epoch = epoch\n",
    "\n",
    "        print()\n",
    "        print()\n",
    "\n",
    "    \n",
    "    ws['N1'] = 'Best False ACC'\n",
    "    ws['O1'] = 'epoch'\n",
    "    ws['N2'] = round(best_false_acc,2)\n",
    "    ws['O2'] = best_false_acc_epoch+1\n",
    "        \n",
    "    ws['N4'] = 'Best False F1'\n",
    "    ws['O4'] = 'epoch'\n",
    "    ws['N5'] = round(best_false_f1,2)\n",
    "    ws['O5'] = best_false_f1_epoch+1\n",
    "        \n",
    "    ws['N7'] = 'Best Pneumonia ACC'\n",
    "    ws['O7'] = 'epoch'\n",
    "    ws['N8'] = round(best_pneumonia_acc,2)\n",
    "    ws['O8'] = best_pneumonia_acc_epoch+1\n",
    "        \n",
    "    ws['N10'] = 'Best Pneumonia F1'\n",
    "    ws['O10'] = 'epoch'\n",
    "    ws['N11'] = round(best_pneumonia_f1,2)\n",
    "    ws['O11'] = best_pneumonia_f1_epoch+1\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    #print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "    # load best model weights\n",
    "    #model.load_state_dict(best_covid_wts)\n",
    "    wb.save('output_excel/현수님세팅_Pneumonia_vs_Fasle(train5475_P 기준세팅)_Balanced(val)_seed_2_BatchNorm_layer_4_bottleneck_2.xlsx') # 엑셀로 저장한다. \n",
    "    #torch.save(model.state_dict(), 'covid_binary.pt')\n",
    "    return model\n",
    "\n",
    "\n",
    "model_ft = models.resnet50(pretrained=True)\n",
    "\n",
    "###BatchNorm Gamma setting###\n",
    "\n",
    "\n",
    "# seed 0,1,2\n",
    "\n",
    "# count =0\n",
    "# bottleneck_count = 0\n",
    "# layer_index=1\n",
    "# layer_name = 'layer'+str(layer_index)\n",
    "# bottleneck_index = 0\n",
    "\n",
    "\n",
    "\n",
    "# count =0\n",
    "# bottleneck_count = 0\n",
    "# layer_index=4\n",
    "# layer_name = 'layer'+str(layer_index)\n",
    "# bottleneck_index = 0\n",
    "\n",
    "\n",
    "count =0\n",
    "bottleneck_count = 0\n",
    "layer_index=4\n",
    "layer_name = 'layer'+str(layer_index)\n",
    "bottleneck_index = 2\n",
    "\n",
    "\n",
    "\n",
    "for name, layer in model_ft.named_children():\n",
    "    if bottleneck_count > 0:\n",
    "        bottleneck_index = 0\n",
    "    if name == layer_name:\n",
    "        bn_index = 1\n",
    "        for name, param in model_ft.named_parameters():\n",
    "            if name == layer_name + '.' + str(bottleneck_index) + '.' + 'bn1.weight':\n",
    "                print(str(layer_name + \"의 \" + str(bottleneck_index)+ \"번째-bottleneck의 \" + 'bn1.weight'))\n",
    "                torch.nn.init.ones_(param)\n",
    "                print(name + '의 gammm one setting 완료')\n",
    "                print()\n",
    "                \n",
    "            elif name == layer_name + '.' + str(bottleneck_index) + '.' + 'bn2.weight':\n",
    "                print(str(layer_name + \"의 \" + str(bottleneck_index)+ \"번째-bottleneck의 \" + 'bn2.weight'))\n",
    "                torch.nn.init.ones_(param)\n",
    "                print(name + '의 gammm one setting 완료')\n",
    "                print()\n",
    "\n",
    "            elif name == layer_name + '.' + str(bottleneck_index) + '.' + 'bn3.weight':\n",
    "                print(str(layer_name + \"의 \" + str(bottleneck_index)+ \"번째-bottleneck의 \" + 'bn3.weight'))\n",
    "                torch.nn.init.zeros_(param)\n",
    "                print(name + '의 gammm zero setting 완료')\n",
    "                print()\n",
    "\n",
    "            elif name == layer_name + '.' + str(bottleneck_index) + '.' + 'bn' + str(bn_index) + '.bias':\n",
    "                print(str(layer_name + \"의 \" + str(bottleneck_index)+ \"번째-bottleneck의 \" + 'bn' + str(bn_index) + '.bias'))\n",
    "                torch.nn.init.zeros_(param)\n",
    "                bn_index = bn_index + 1\n",
    "                if name == layer_name + '.' + str(bottleneck_index) + '.' + 'bn3.bias':\n",
    "                    bottleneck_index = bottleneck_index + 1\n",
    "                    bn_index = 1\n",
    "                print(name + '의 beta zero setting 완료')\n",
    "                print()\n",
    "\n",
    "        bottleneck_count = bottleneck_count + 1\n",
    "        layer_index = layer_index+ 1\n",
    "        layer_name = 'layer'+str(layer_index)     \n",
    "\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)\n",
    "#exp_lr_scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max, eta_min=0, last_epoch=-1, verbose=False)\n",
    "exp_lr_scheduler = GradualWarmupScheduler(optimizer_ft, multiplier=1, total_epoch=5, after_scheduler=exp_lr_scheduler)\n",
    "#exp_lr_scheduler = cosine_annearing_with_warmup.CosineAnnealingWarmUpRestarts(optimizer_ft, T_0=30, T_mult=1, eta_max=0.001, T_up=20)\n",
    "\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=20)\n",
    "\n",
    "# freeze backbone layers\n",
    "'''\n",
    "count = 0\n",
    "for child_name, param in model_ft.named_children():\n",
    "    for param_name, param_param in model_ft.named_parameters():\n",
    "        if child_name == 'layer4': \n",
    "            param_param.requires_grad = True\n",
    "        else:\n",
    "            param_param.requires_grad = False\n",
    "'''\n",
    "\n",
    "\n",
    "#특정 conv layer 이후 초기화\n",
    "'''\n",
    "children_index = 4\n",
    "children_name = 'layer'+str(children_index)\n",
    "bottleneck_index = 2\n",
    "for name, layer in model_ft.named_children():\n",
    "    if name == children_name:\n",
    "        conv_index = 1\n",
    "        for name, param in model_ft.named_parameters():\n",
    "            if name == children_name + \".\" + str(bottleneck_index) + '.' + 'conv' + str(conv_index) + '.weight':\n",
    "                print(children_name + \"의 \"+ str(bottleneck_index)+ \"번째-bottleneck의 \" + 'conv' +str(conv_index) + '.weight')\n",
    "                torch.nn.init.xavier_uniform_(param)\n",
    "                print(name + '의 conv filter initilization setting 완료')\n",
    "                print()\n",
    "                conv_index = conv_index + 1\n",
    "                if name == 'layer3.' + str(bottleneck_index) + '.' + 'conv3.weight':\n",
    "                    bottleneck_index = bottleneck_index + 1\n",
    "                    conv_index = 1\n",
    "                elif name == 'layer4.' + str(bottleneck_index) + '.' + 'conv3.weight':\n",
    "                    bottleneck_index = bottleneck_index + 1\n",
    "                    conv_index = 1\n",
    "        children_index = children_index + 1\n",
    "        children_name = 'layer'+str(children_index)\n",
    "        bottleneck_index = 0\n",
    "'''        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#increase fine-tune layer per epoch\n",
    "'''\n",
    "if epoch < 6:\n",
    "    # freeze backbone layers\n",
    "    for param in net.parameters():\n",
    "        count +=1\n",
    "        if count < 4: #freezing first 3 layers\n",
    "            param.requires_grad = False    \n",
    "        else:\n",
    "            for param in net.parameters():\n",
    "                aram.requires_grad = True\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seed 0 _  Mistake code _ layer 4 bottindex 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 10950\n",
      "Validation dataset size: 300\n",
      "['false', 'pneumonia']\n",
      "######### Validation Dataset #########\n",
      "false size: 200\n",
      "pneumonia size: 100\n",
      "layer4의 0번째-bottleneck의 bn1.weight\n",
      "layer4.0.bn1.weight의 gammm one setting 완료\n",
      "\n",
      "layer4의 0번째-bottleneck의 bn1.bias\n",
      "layer4.0.bn1.bias의 beta zero setting 완료\n",
      "\n",
      "layer4의 0번째-bottleneck의 bn2.weight\n",
      "layer4.0.bn2.weight의 gammm one setting 완료\n",
      "\n",
      "layer4의 0번째-bottleneck의 bn2.bias\n",
      "layer4.0.bn2.bias의 beta zero setting 완료\n",
      "\n",
      "layer4의 0번째-bottleneck의 bn3.weight\n",
      "layer4.0.bn3.weight의 gammm zero setting 완료\n",
      "\n",
      "layer4의 0번째-bottleneck의 bn3.bias\n",
      "layer4.0.bn3.bias의 beta zero setting 완료\n",
      "\n",
      "Epoch 0/19\n",
      "----------\n",
      "val Loss: 0.6366 Acc: 65.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 92.0\n",
      "False Precision: 67.65\n",
      "False ACC: 65.33\n",
      "False F1 score: 77.97\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 12.0\n",
      "Pneumonia Precision: 42.86\n",
      "Pneumonia ACC: 65.33\n",
      "Pneumonia F1 score: 18.75\n",
      "\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "val Loss: 0.4134 Acc: 82.0000\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 76.0\n",
      "False Precision: 96.2\n",
      "False ACC: 82.0\n",
      "False F1 score: 84.92\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 66.2\n",
      "Pneumonia ACC: 82.0\n",
      "Pneumonia F1 score: 77.69\n",
      "\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "val Loss: 0.2877 Acc: 86.0000\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 83.0\n",
      "False Precision: 95.39999999999999\n",
      "False ACC: 86.0\n",
      "False F1 score: 88.77\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 92.0\n",
      "Pneumonia Precision: 73.02\n",
      "Pneumonia ACC: 86.0\n",
      "Pneumonia F1 score: 81.42\n",
      "\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "val Loss: 0.5475 Acc: 79.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 71.0\n",
      "False Precision: 97.26\n",
      "False ACC: 79.33\n",
      "False F1 score: 82.08\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 96.0\n",
      "Pneumonia Precision: 62.339999999999996\n",
      "Pneumonia ACC: 79.33\n",
      "Pneumonia F1 score: 75.59\n",
      "\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "val Loss: 0.5036 Acc: 76.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 67.0\n",
      "False Precision: 96.39999999999999\n",
      "False ACC: 76.33\n",
      "False F1 score: 79.06\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 95.0\n",
      "Pneumonia Precision: 59.01\n",
      "Pneumonia ACC: 76.33\n",
      "Pneumonia F1 score: 72.8\n",
      "\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "val Loss: 0.1875 Acc: 93.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 95.0\n",
      "False Precision: 95.0\n",
      "False ACC: 93.33\n",
      "False F1 score: 95.0\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 90.0\n",
      "Pneumonia Precision: 90.0\n",
      "Pneumonia ACC: 93.33\n",
      "Pneumonia F1 score: 90.0\n",
      "\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "val Loss: 0.1961 Acc: 93.0000\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 93.0\n",
      "False Precision: 96.37\n",
      "False ACC: 93.0\n",
      "False F1 score: 94.66\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 93.0\n",
      "Pneumonia Precision: 86.92\n",
      "Pneumonia ACC: 93.0\n",
      "Pneumonia F1 score: 89.86\n",
      "\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "val Loss: 0.2552 Acc: 91.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 91.5\n",
      "False Precision: 95.81\n",
      "False ACC: 91.67\n",
      "False F1 score: 93.61\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 92.0\n",
      "Pneumonia Precision: 84.39999999999999\n",
      "Pneumonia ACC: 91.67\n",
      "Pneumonia F1 score: 88.04\n",
      "\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "val Loss: 0.2423 Acc: 89.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 86.5\n",
      "False Precision: 97.74000000000001\n",
      "False ACC: 89.67\n",
      "False F1 score: 91.78\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 96.0\n",
      "Pneumonia Precision: 78.05\n",
      "Pneumonia ACC: 89.67\n",
      "Pneumonia F1 score: 86.1\n",
      "\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "val Loss: 0.2556 Acc: 91.0000\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 89.5\n",
      "False Precision: 96.76\n",
      "False ACC: 91.0\n",
      "False F1 score: 92.99\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 81.74\n",
      "Pneumonia ACC: 91.0\n",
      "Pneumonia F1 score: 87.44\n",
      "\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "val Loss: 0.2211 Acc: 92.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 91.5\n",
      "False Precision: 96.83\n",
      "False ACC: 92.33\n",
      "False F1 score: 94.09\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 84.68\n",
      "Pneumonia ACC: 92.33\n",
      "Pneumonia F1 score: 89.1\n",
      "\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "val Loss: 0.2502 Acc: 90.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 89.0\n",
      "False Precision: 96.74000000000001\n",
      "False ACC: 90.67\n",
      "False F1 score: 92.71\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 81.03\n",
      "Pneumonia ACC: 90.67\n",
      "Pneumonia F1 score: 87.03\n",
      "\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "val Loss: 0.2721 Acc: 89.0000\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 86.5\n",
      "False Precision: 96.65\n",
      "False ACC: 89.0\n",
      "False F1 score: 91.29\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 77.69\n",
      "Pneumonia ACC: 89.0\n",
      "Pneumonia F1 score: 85.07\n",
      "\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "val Loss: 0.2493 Acc: 91.0000\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 89.5\n",
      "False Precision: 96.76\n",
      "False ACC: 91.0\n",
      "False F1 score: 92.99\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 81.74\n",
      "Pneumonia ACC: 91.0\n",
      "Pneumonia F1 score: 87.44\n",
      "\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "val Loss: 0.2782 Acc: 90.0000\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 88.0\n",
      "False Precision: 96.7\n",
      "False ACC: 90.0\n",
      "False F1 score: 92.15\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 79.66\n",
      "Pneumonia ACC: 90.0\n",
      "Pneumonia F1 score: 86.24\n",
      "\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "val Loss: 0.1959 Acc: 93.0000\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 92.5\n",
      "False Precision: 96.86\n",
      "False ACC: 93.0\n",
      "False F1 score: 94.63\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 86.24000000000001\n",
      "Pneumonia ACC: 93.0\n",
      "Pneumonia F1 score: 89.95\n",
      "\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "val Loss: 0.2448 Acc: 91.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 90.0\n",
      "False Precision: 96.77\n",
      "False ACC: 91.33\n",
      "False F1 score: 93.26\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 82.46\n",
      "Pneumonia ACC: 91.33\n",
      "Pneumonia F1 score: 87.85\n",
      "\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "val Loss: 0.2159 Acc: 91.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 90.5\n",
      "False Precision: 96.78999999999999\n",
      "False ACC: 91.67\n",
      "False F1 score: 93.54\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 83.19\n",
      "Pneumonia ACC: 91.67\n",
      "Pneumonia F1 score: 88.27\n",
      "\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "val Loss: 0.2118 Acc: 92.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 91.5\n",
      "False Precision: 96.83\n",
      "False ACC: 92.33\n",
      "False F1 score: 94.09\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 84.68\n",
      "Pneumonia ACC: 92.33\n",
      "Pneumonia F1 score: 89.1\n",
      "\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "val Loss: 0.2214 Acc: 92.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 91.5\n",
      "False Precision: 96.83\n",
      "False ACC: 92.33\n",
      "False F1 score: 94.09\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 84.68\n",
      "Pneumonia ACC: 92.33\n",
      "Pneumonia F1 score: 89.1\n",
      "\n",
      "\n",
      "Training complete in 34m 10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nif epoch < 6:\\n    # freeze backbone layers\\n    for param in net.parameters():\\n        count +=1\\n        if count < 4: #freezing first 3 layers\\n            param.requires_grad = False    \\n        else:\\n            for param in net.parameters():\\n                aram.requires_grad = True\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Author: Sasank Chilamkurthy\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "from openpyxl import Workbook\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "# from pytorch_cosine_annealing_warmup_master import cosine_annearing_with_warmup\n",
    "import random\n",
    "\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "#torch.set_deterministic(True)\n",
    "random_seed = 0\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.3)),\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.15,0.1)),\n",
    "        transforms.RandomAffine(degrees=(-10,10)),\n",
    "        transforms.Resize(280),\n",
    "        transforms.CenterCrop(224),\n",
    "        #transforms.Resize(size=(224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        transforms.Normalize([0.493, 0.493, 0.493], [0.246, 0.246, 0.246])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        #transforms.Resize(size=(224,224)),\n",
    "        transforms.Resize(280),\n",
    "        transforms.CenterCrop(224),\n",
    "        #transforms.Resize(size=(224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        transforms.Normalize([0.493, 0.493, 0.493], [0.246, 0.246, 0.246])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = '/home/aiffel/Hackathon_covid_19/data_2'\n",
    "#data_dir = 'Crop_CXR/binary_covid'\n",
    "batch_size = 16\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "val_class_names = image_datasets['val'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Training dataset size: \" + str(dataset_sizes['train']))\n",
    "print(\"Validation dataset size: \" +str(dataset_sizes['val']))\n",
    "print(val_class_names)\n",
    "\n",
    "\n",
    "val_dir = '/home/aiffel/Hackathon_covid_19/data_2/val/'\n",
    "false_data_dir = val_dir + 'false'\n",
    "pneumonia_data_dir = val_dir + 'pneumonia'\n",
    "\n",
    "print(\"######### Validation Dataset #########\")\n",
    "val_false_num = len(os.listdir(false_data_dir))\n",
    "val_pneumonia_num = len(os.listdir(pneumonia_data_dir))\n",
    "print(\"false size: \" + str(val_false_num))\n",
    "print(\"pneumonia size: \" + str(val_pneumonia_num))\n",
    "\n",
    "wb = Workbook()      # 워크북을 생성한다.\n",
    "ws = wb.active       # 워크 시트를 얻는다.\n",
    "    \n",
    "ws['A1'] = 'ResNet50'\n",
    "ws['B1'] = 'Val ACC'\n",
    "\n",
    "ws['D1'] = 'False ACC'\n",
    "ws['E1'] = 'False Recall'\n",
    "ws['F1'] = 'False Precision'\n",
    "ws['G1'] = 'False F1'\n",
    "\n",
    "ws['I1'] = 'Penumonia ACC'\n",
    "ws['J1'] = 'Penumonia Recall'\n",
    "ws['K1'] = 'Penumonia Precision'\n",
    "ws['L1'] = 'Penumonia F1'\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    best_false_acc = 0.0\n",
    "    best_false_f1 = 0.0\n",
    "    best_pneumonia_acc = 0.0\n",
    "    best_pneumonia_f1 = 0.0\n",
    "\n",
    "    best_false_acc_epoch = 0\n",
    "    best_false_f1_epoch = 0\n",
    "    best_pneumonia_acc_epoch = 0\n",
    "    best_pneumonia_f1_epoch = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        val_false_TP = 0.0\n",
    "        val_pneumonia_TP = 0.0\n",
    "        val_false_FN = 0.0\n",
    "        val_pneumonia_FN = 0.0\n",
    "        val_false_TN = 0.0\n",
    "        val_pneumonia_TN = 0.0\n",
    "        val_false_FP = 0.0\n",
    "        val_pneumonia_FP = 0.0\n",
    "\n",
    "        \n",
    "        \n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        A = 'A'+str(epoch+2)\n",
    "        ws[A] = 'Epoch' + str(epoch+1)\n",
    "    \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    #outputs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    # Append batch prediction results\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                a = preds.size()\n",
    "                b = a[0]\n",
    "                \n",
    "                if phase == 'val':\n",
    "                    for i in range(b):\n",
    "                        if preds[i].item() == labels.data[i].item():\n",
    "                            #Normal-index:0, Pneumonia-index:1\n",
    "                            if preds.data[i].item() == 0: \n",
    "                                val_false_TP += 1 #Normal 관점에서는 normal를 정확히 분류하는 것이 TP\n",
    "                                val_pneumonia_TN += 1 #Pneumonia 관점에서는 normal를 정확히 분류하는 것이 TN\n",
    "                            elif preds.data[i].item() == 1: \n",
    "                                val_pneumonia_TP += 1 #Pneumonia 관점에서는 Pneumonia를 정확히 분류하는 것이 TP\n",
    "                                val_false_TN += 1 #Normal 관점에서는 Pneumonia를 정확히 분류하는 것이 TN\n",
    "\n",
    "                        if preds[i].item() != labels.data[i].item():\n",
    "                            if preds.data[i].item() == 0:\n",
    "                                val_false_FP += 1 #Normal 관점에서 normal라고 분류했지만 실제로는 pneumonia인 경우는 FP\n",
    "                                val_pneumonia_FN += 1 #Pneumonia 관점에서 normal라고 분류했지만 실제로는 pneumonia인 경우는 FN\n",
    "                            elif preds.data[i].item() == 1:\n",
    "                                val_pneumonia_FP += 1 #Normal 관점에서 pneumonia라고 분류했지만 실제로는 normal인 경우는 FP\n",
    "                                val_false_FN += 1 #Pneumonia 관점에서 pneumonia라고 분류했지만 실제로는 normal인 경우는 FN\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                \n",
    "            \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "           \n",
    "            if phase == 'val':\n",
    "                B = 'B'+str(epoch+2)\n",
    "                ws[B] = '{:.4f}'.format(epoch_acc*100)\n",
    "\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, (epoch_acc*100)))    \n",
    "\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "\n",
    "        #recall, precision -> https://en.wikipedia.org/wiki/Precision_and_recall\n",
    "        #recall = TP/(TP+FN)\n",
    "        #precision = TP/(TP+FP)\n",
    "        #ACC = (TP+TN)/(TP+TN+FP+FN)\n",
    "        false_recall = round(val_false_TP/(val_false_TP + val_false_FN),4)*100\n",
    "        pneumonia_recall = round(val_pneumonia_TP/(val_pneumonia_TP + val_pneumonia_FN),4)*100\n",
    "        false_precision = round(val_false_TP/(val_false_TP + val_false_FP),4)*100\n",
    "        pneumonia_precision = round(val_pneumonia_TP/(val_pneumonia_TP + val_pneumonia_FP),4)*100\n",
    "        false_acc = round((val_false_TP + val_false_TN)/(val_false_TP + val_false_FP +val_false_TN + val_false_FN),4)*100\n",
    "        pneumonia_acc = round((val_pneumonia_TP + val_pneumonia_TN)/(val_pneumonia_TP + val_pneumonia_FP +val_pneumonia_TN + val_pneumonia_FN),4)*100\n",
    "        #F1 score -> https://en.wikipedia.org/wiki/F-score\n",
    "        #F1 score = 2/((1/recall)+(1/precision)) = 2((precision*recall)/(precision+recall)) = tp/(tp+((1/2)(fp+fn)))\n",
    "        false_f1_score = round(2*(false_precision*false_recall)/(false_precision+false_recall),2)\n",
    "        pneumonia_f1_score = round(2*(pneumonia_precision*pneumonia_recall)/(pneumonia_precision+pneumonia_recall),2)\n",
    "\n",
    "        #total_data = batch size --> covid_total_dataset = false_total_dataset\n",
    "        false_total_dataset = int(val_false_TP + val_false_FP +val_false_TN + val_false_FN)\n",
    "        pneumonia_total_dataset = int(val_pneumonia_TP + val_pneumonia_FP +val_pneumonia_TN + val_pneumonia_FN)\n",
    "        \n",
    "      \n",
    "        D = 'D'+str(epoch+2)\n",
    "        E = 'E'+str(epoch+2)\n",
    "        F = 'F'+str(epoch+2)\n",
    "        G = 'G'+str(epoch+2)\n",
    "        \n",
    "        I = 'I'+str(epoch+2)\n",
    "        J = 'J'+str(epoch+2)\n",
    "        K = 'K'+str(epoch+2)\n",
    "        L = 'L'+str(epoch+2)\n",
    "\n",
    "        ws[D] = false_acc\n",
    "        ws[E] = false_recall\n",
    "        ws[F] = false_precision\n",
    "        ws[G] = false_f1_score\n",
    "        \n",
    "        ws[I] = pneumonia_acc\n",
    "        ws[J] = pneumonia_recall\n",
    "        ws[K] = pneumonia_precision\n",
    "        ws[L] = pneumonia_f1_score\n",
    "\n",
    "\n",
    "        print()\n",
    "\n",
    "        print('데이터셋A: ' + str(false_total_dataset))\n",
    "        print('False Recall: ' + str(false_recall))        \n",
    "        print('False Precision: ' + str(false_precision))\n",
    "        print('False ACC: ' + str(false_acc))\n",
    "        print('False F1 score: ' + str(false_f1_score))\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        print('데이터셋B: ' + str(pneumonia_total_dataset))\n",
    "        print('Pneumonia Recall: ' + str(pneumonia_recall))\n",
    "        print('Pneumonia Precision: ' + str(pneumonia_precision))\n",
    "        print('Pneumonia ACC: ' + str(pneumonia_acc))\n",
    "        print('Pneumonia F1 score: ' + str(pneumonia_f1_score))\n",
    "        \n",
    "  \n",
    "        if phase == 'val' and false_acc > best_false_acc:\n",
    "            best_false_acc = false_acc\n",
    "            best_false_acc_epoch = epoch\n",
    "\n",
    "        if phase == 'val' and pneumonia_acc > best_pneumonia_acc:\n",
    "            best_pneumonia_acc = pneumonia_acc\n",
    "            best_pneumonia_acc_epoch = epoch\n",
    "            \n",
    "\n",
    "        if phase == 'val' and false_f1_score > best_false_f1:\n",
    "            best_false_f1 = false_f1_score\n",
    "            best_false_f1_epoch = epoch\n",
    "            \n",
    "        if phase == 'val' and pneumonia_f1_score > best_pneumonia_f1:\n",
    "            best_pneumonia_f1 = pneumonia_f1_score\n",
    "            best_pneumonia_f1_epoch = epoch\n",
    "\n",
    "        print()\n",
    "        print()\n",
    "\n",
    "    \n",
    "    ws['N1'] = 'Best False ACC'\n",
    "    ws['O1'] = 'epoch'\n",
    "    ws['N2'] = round(best_false_acc,2)\n",
    "    ws['O2'] = best_false_acc_epoch+1\n",
    "        \n",
    "    ws['N4'] = 'Best False F1'\n",
    "    ws['O4'] = 'epoch'\n",
    "    ws['N5'] = round(best_false_f1,2)\n",
    "    ws['O5'] = best_false_f1_epoch+1\n",
    "        \n",
    "    ws['N7'] = 'Best Pneumonia ACC'\n",
    "    ws['O7'] = 'epoch'\n",
    "    ws['N8'] = round(best_pneumonia_acc,2)\n",
    "    ws['O8'] = best_pneumonia_acc_epoch+1\n",
    "        \n",
    "    ws['N10'] = 'Best Pneumonia F1'\n",
    "    ws['O10'] = 'epoch'\n",
    "    ws['N11'] = round(best_pneumonia_f1,2)\n",
    "    ws['O11'] = best_pneumonia_f1_epoch+1\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    #print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "    # load best model weights\n",
    "    #model.load_state_dict(best_covid_wts)\n",
    "    wb.save('output_excel/현수님세팅_Pneumonia_vs_Fasle(train5475_P 기준세팅)_Balanced(val)_seed_0_Mistake_layer_4_bottleneck_0.xlsx') # 엑셀로 저장한다. \n",
    "    #torch.save(model.state_dict(), 'covid_binary.pt')\n",
    "    return model\n",
    "\n",
    "\n",
    "model_ft = models.resnet50(pretrained=True)\n",
    "\n",
    "\n",
    "###BatchNorm Gamma setting###\n",
    "\n",
    "count =0\n",
    "layer_index=4\n",
    "layer_name = 'layer'+str(layer_index)\n",
    "\n",
    "for name, layer in model_ft.named_children():\n",
    "    if name == layer_name:\n",
    "        bottleneck_index = 0\n",
    "        bn_index = 1\n",
    "        for name, param in model_ft.named_parameters():\n",
    "            if name == layer_name + '.' + str(bottleneck_index) + '.' + 'bn1.weight':\n",
    "                print(str(layer_name + \"의 \" + str(bottleneck_index)+ \"번째-bottleneck의 \" + 'bn1.weight'))\n",
    "                torch.nn.init.ones_(param)\n",
    "                print(name + '의 gammm one setting 완료')\n",
    "                print()\n",
    "                \n",
    "            elif name == layer_name + '.' + str(bottleneck_index) + '.' + 'bn2.weight':\n",
    "                print(str(layer_name + \"의 \" + str(bottleneck_index)+ \"번째-bottleneck의 \" + 'bn2.weight'))\n",
    "                torch.nn.init.ones_(param)\n",
    "                print(name + '의 gammm one setting 완료')\n",
    "                print()\n",
    "\n",
    "            elif name == layer_name + '.' + str(bottleneck_index) + '.' + 'bn3.weight':\n",
    "                print(str(layer_name + \"의 \" + str(bottleneck_index)+ \"번째-bottleneck의 \" + 'bn3.weight'))\n",
    "                torch.nn.init.ones_(param)\n",
    "                print(name + '의 gammm zero setting 완료')\n",
    "                print()\n",
    "\n",
    "            elif name == layer_name + '.' + str(bottleneck_index) + '.' + 'bn' + str(bn_index) + '.bias':\n",
    "                print(str(layer_name + \"의 \" + str(bottleneck_index)+ \"번째-bottleneck의 \" + 'bn' + str(bn_index) + '.bias'))\n",
    "                torch.nn.init.zeros_(param)\n",
    "                bn_index = bn_index + 1\n",
    "                print(name + '의 beta zero setting 완료')\n",
    "                print()\n",
    "\n",
    "\n",
    "\n",
    "        bottleneck_index = bottleneck_index + 1\n",
    "\n",
    "        layer_index = layer_index+ 1\n",
    "        layer_name = 'layer'+str(layer_index)     \n",
    "\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)\n",
    "#exp_lr_scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max, eta_min=0, last_epoch=-1, verbose=False)\n",
    "exp_lr_scheduler = GradualWarmupScheduler(optimizer_ft, multiplier=1, total_epoch=5, after_scheduler=exp_lr_scheduler)\n",
    "#exp_lr_scheduler = cosine_annearing_with_warmup.CosineAnnealingWarmUpRestarts(optimizer_ft, T_0=30, T_mult=1, eta_max=0.001, T_up=20)\n",
    "\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=20)\n",
    "\n",
    "# freeze backbone layers\n",
    "'''\n",
    "count = 0\n",
    "for child_name, param in model_ft.named_children():\n",
    "    for param_name, param_param in model_ft.named_parameters():\n",
    "        if child_name == 'layer4': \n",
    "            param_param.requires_grad = True\n",
    "        else:\n",
    "            param_param.requires_grad = False\n",
    "'''\n",
    "\n",
    "\n",
    "#특정 conv layer 이후 초기화\n",
    "'''\n",
    "children_index = 4\n",
    "children_name = 'layer'+str(children_index)\n",
    "bottleneck_index = 2\n",
    "for name, layer in model_ft.named_children():\n",
    "    if name == children_name:\n",
    "        conv_index = 1\n",
    "        for name, param in model_ft.named_parameters():\n",
    "            if name == children_name + \".\" + str(bottleneck_index) + '.' + 'conv' + str(conv_index) + '.weight':\n",
    "                print(children_name + \"의 \"+ str(bottleneck_index)+ \"번째-bottleneck의 \" + 'conv' +str(conv_index) + '.weight')\n",
    "                torch.nn.init.xavier_uniform_(param)\n",
    "                print(name + '의 conv filter initilization setting 완료')\n",
    "                print()\n",
    "                conv_index = conv_index + 1\n",
    "                if name == 'layer3.' + str(bottleneck_index) + '.' + 'conv3.weight':\n",
    "                    bottleneck_index = bottleneck_index + 1\n",
    "                    conv_index = 1\n",
    "                elif name == 'layer4.' + str(bottleneck_index) + '.' + 'conv3.weight':\n",
    "                    bottleneck_index = bottleneck_index + 1\n",
    "                    conv_index = 1\n",
    "        children_index = children_index + 1\n",
    "        children_name = 'layer'+str(children_index)\n",
    "        bottleneck_index = 0\n",
    "'''        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#increase fine-tune layer per epoch\n",
    "'''\n",
    "if epoch < 6:\n",
    "    # freeze backbone layers\n",
    "    for param in net.parameters():\n",
    "        count +=1\n",
    "        if count < 4: #freezing first 3 layers\n",
    "            param.requires_grad = False    \n",
    "        else:\n",
    "            for param in net.parameters():\n",
    "                aram.requires_grad = True\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seed 1 _  Mistake code _ layer 4 bottindex 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 10950\n",
      "Validation dataset size: 300\n",
      "['false', 'pneumonia']\n",
      "######### Validation Dataset #########\n",
      "false size: 200\n",
      "pneumonia size: 100\n",
      "layer4의 0번째-bottleneck의 bn1.weight\n",
      "layer4.0.bn1.weight의 gammm one setting 완료\n",
      "\n",
      "layer4의 0번째-bottleneck의 bn1.bias\n",
      "layer4.0.bn1.bias의 beta zero setting 완료\n",
      "\n",
      "layer4의 0번째-bottleneck의 bn2.weight\n",
      "layer4.0.bn2.weight의 gammm one setting 완료\n",
      "\n",
      "layer4의 0번째-bottleneck의 bn2.bias\n",
      "layer4.0.bn2.bias의 beta zero setting 완료\n",
      "\n",
      "layer4의 0번째-bottleneck의 bn3.weight\n",
      "layer4.0.bn3.weight의 gammm zero setting 완료\n",
      "\n",
      "layer4의 0번째-bottleneck의 bn3.bias\n",
      "layer4.0.bn3.bias의 beta zero setting 완료\n",
      "\n",
      "Epoch 0/19\n",
      "----------\n",
      "val Loss: 0.7906 Acc: 35.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 10.5\n",
      "False Precision: 60.0\n",
      "False ACC: 35.67\n",
      "False F1 score: 17.87\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 86.0\n",
      "Pneumonia Precision: 32.45\n",
      "Pneumonia ACC: 35.67\n",
      "Pneumonia F1 score: 47.12\n",
      "\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "val Loss: 0.3237 Acc: 86.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 83.5\n",
      "False Precision: 95.43\n",
      "False ACC: 86.33\n",
      "False F1 score: 89.07\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 92.0\n",
      "Pneumonia Precision: 73.6\n",
      "Pneumonia ACC: 86.33\n",
      "Pneumonia F1 score: 81.78\n",
      "\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "val Loss: 0.2813 Acc: 88.0000\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 86.0\n",
      "False Precision: 95.56\n",
      "False ACC: 88.0\n",
      "False F1 score: 90.53\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 92.0\n",
      "Pneumonia Precision: 76.67\n",
      "Pneumonia ACC: 88.0\n",
      "Pneumonia F1 score: 83.64\n",
      "\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "val Loss: 0.2615 Acc: 87.0000\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 84.0\n",
      "False Precision: 96.0\n",
      "False ACC: 87.0\n",
      "False F1 score: 89.6\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 93.0\n",
      "Pneumonia Precision: 74.4\n",
      "Pneumonia ACC: 87.0\n",
      "Pneumonia F1 score: 82.67\n",
      "\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "val Loss: 0.3854 Acc: 81.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 76.0\n",
      "False Precision: 95.6\n",
      "False ACC: 81.67\n",
      "False F1 score: 84.68\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 93.0\n",
      "Pneumonia Precision: 65.96\n",
      "Pneumonia ACC: 81.67\n",
      "Pneumonia F1 score: 77.18\n",
      "\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "val Loss: 0.2992 Acc: 85.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 81.5\n",
      "False Precision: 96.45\n",
      "False ACC: 85.67\n",
      "False F1 score: 88.35\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 71.76\n",
      "Pneumonia ACC: 85.67\n",
      "Pneumonia F1 score: 81.39\n",
      "\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "val Loss: 0.2166 Acc: 91.0000\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 88.5\n",
      "False Precision: 97.78999999999999\n",
      "False ACC: 91.0\n",
      "False F1 score: 92.91\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 96.0\n",
      "Pneumonia Precision: 80.67\n",
      "Pneumonia ACC: 91.0\n",
      "Pneumonia F1 score: 87.67\n",
      "\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "val Loss: 0.2237 Acc: 92.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 93.0\n",
      "False Precision: 95.88\n",
      "False ACC: 92.67\n",
      "False F1 score: 94.42\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 92.0\n",
      "Pneumonia Precision: 86.79\n",
      "Pneumonia ACC: 92.67\n",
      "Pneumonia F1 score: 89.32\n",
      "\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "val Loss: 0.1748 Acc: 94.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 95.0\n",
      "False Precision: 96.94\n",
      "False ACC: 94.67\n",
      "False F1 score: 95.96\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 90.38000000000001\n",
      "Pneumonia ACC: 94.67\n",
      "Pneumonia F1 score: 92.15\n",
      "\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "val Loss: 0.1946 Acc: 92.0000\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 91.0\n",
      "False Precision: 96.81\n",
      "False ACC: 92.0\n",
      "False F1 score: 93.82\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 83.93\n",
      "Pneumonia ACC: 92.0\n",
      "Pneumonia F1 score: 88.68\n",
      "\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "val Loss: 0.1792 Acc: 92.0000\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 90.5\n",
      "False Precision: 97.31\n",
      "False ACC: 92.0\n",
      "False F1 score: 93.78\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 95.0\n",
      "Pneumonia Precision: 83.33\n",
      "Pneumonia ACC: 92.0\n",
      "Pneumonia F1 score: 88.78\n",
      "\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "val Loss: 0.1694 Acc: 92.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 91.5\n",
      "False Precision: 97.34\n",
      "False ACC: 92.67\n",
      "False F1 score: 94.33\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 95.0\n",
      "Pneumonia Precision: 84.82\n",
      "Pneumonia ACC: 92.67\n",
      "Pneumonia F1 score: 89.62\n",
      "\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "val Loss: 0.1839 Acc: 92.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 91.5\n",
      "False Precision: 97.34\n",
      "False ACC: 92.67\n",
      "False F1 score: 94.33\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 95.0\n",
      "Pneumonia Precision: 84.82\n",
      "Pneumonia ACC: 92.67\n",
      "Pneumonia F1 score: 89.62\n",
      "\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "val Loss: 0.1721 Acc: 92.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 91.0\n",
      "False Precision: 97.33000000000001\n",
      "False ACC: 92.33\n",
      "False F1 score: 94.06\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 95.0\n",
      "Pneumonia Precision: 84.07\n",
      "Pneumonia ACC: 92.33\n",
      "Pneumonia F1 score: 89.2\n",
      "\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "val Loss: 0.1787 Acc: 92.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 91.0\n",
      "False Precision: 97.33000000000001\n",
      "False ACC: 92.33\n",
      "False F1 score: 94.06\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 95.0\n",
      "Pneumonia Precision: 84.07\n",
      "Pneumonia ACC: 92.33\n",
      "Pneumonia F1 score: 89.2\n",
      "\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "val Loss: 0.1638 Acc: 93.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 92.5\n",
      "False Precision: 97.37\n",
      "False ACC: 93.33\n",
      "False F1 score: 94.87\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 95.0\n",
      "Pneumonia Precision: 86.36\n",
      "Pneumonia ACC: 93.33\n",
      "Pneumonia F1 score: 90.47\n",
      "\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "val Loss: 0.1719 Acc: 92.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 91.5\n",
      "False Precision: 97.34\n",
      "False ACC: 92.67\n",
      "False F1 score: 94.33\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 95.0\n",
      "Pneumonia Precision: 84.82\n",
      "Pneumonia ACC: 92.67\n",
      "Pneumonia F1 score: 89.62\n",
      "\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "val Loss: 0.1785 Acc: 92.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 92.0\n",
      "False Precision: 96.84\n",
      "False ACC: 92.67\n",
      "False F1 score: 94.36\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 85.45\n",
      "Pneumonia ACC: 92.67\n",
      "Pneumonia F1 score: 89.52\n",
      "\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "val Loss: 0.1568 Acc: 92.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 92.0\n",
      "False Precision: 96.84\n",
      "False ACC: 92.67\n",
      "False F1 score: 94.36\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 85.45\n",
      "Pneumonia ACC: 92.67\n",
      "Pneumonia F1 score: 89.52\n",
      "\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "val Loss: 0.1690 Acc: 93.0000\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 92.5\n",
      "False Precision: 96.86\n",
      "False ACC: 93.0\n",
      "False F1 score: 94.63\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 86.24000000000001\n",
      "Pneumonia ACC: 93.0\n",
      "Pneumonia F1 score: 89.95\n",
      "\n",
      "\n",
      "Training complete in 32m 59s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nif epoch < 6:\\n    # freeze backbone layers\\n    for param in net.parameters():\\n        count +=1\\n        if count < 4: #freezing first 3 layers\\n            param.requires_grad = False    \\n        else:\\n            for param in net.parameters():\\n                aram.requires_grad = True\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Author: Sasank Chilamkurthy\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "from openpyxl import Workbook\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "# from pytorch_cosine_annealing_warmup_master import cosine_annearing_with_warmup\n",
    "import random\n",
    "\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "#torch.set_deterministic(True)\n",
    "random_seed = 1\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.3)),\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.15,0.1)),\n",
    "        transforms.RandomAffine(degrees=(-10,10)),\n",
    "        transforms.Resize(280),\n",
    "        transforms.CenterCrop(224),\n",
    "        #transforms.Resize(size=(224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        transforms.Normalize([0.493, 0.493, 0.493], [0.246, 0.246, 0.246])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        #transforms.Resize(size=(224,224)),\n",
    "        transforms.Resize(280),\n",
    "        transforms.CenterCrop(224),\n",
    "        #transforms.Resize(size=(224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        transforms.Normalize([0.493, 0.493, 0.493], [0.246, 0.246, 0.246])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = '/home/aiffel/Hackathon_covid_19/data_2'\n",
    "#data_dir = 'Crop_CXR/binary_covid'\n",
    "batch_size = 16\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "val_class_names = image_datasets['val'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Training dataset size: \" + str(dataset_sizes['train']))\n",
    "print(\"Validation dataset size: \" +str(dataset_sizes['val']))\n",
    "print(val_class_names)\n",
    "\n",
    "\n",
    "val_dir = '/home/aiffel/Hackathon_covid_19/data_2/val/'\n",
    "false_data_dir = val_dir + 'false'\n",
    "pneumonia_data_dir = val_dir + 'pneumonia'\n",
    "\n",
    "print(\"######### Validation Dataset #########\")\n",
    "val_false_num = len(os.listdir(false_data_dir))\n",
    "val_pneumonia_num = len(os.listdir(pneumonia_data_dir))\n",
    "print(\"false size: \" + str(val_false_num))\n",
    "print(\"pneumonia size: \" + str(val_pneumonia_num))\n",
    "\n",
    "wb = Workbook()      # 워크북을 생성한다.\n",
    "ws = wb.active       # 워크 시트를 얻는다.\n",
    "    \n",
    "ws['A1'] = 'ResNet50'\n",
    "ws['B1'] = 'Val ACC'\n",
    "\n",
    "ws['D1'] = 'False ACC'\n",
    "ws['E1'] = 'False Recall'\n",
    "ws['F1'] = 'False Precision'\n",
    "ws['G1'] = 'False F1'\n",
    "\n",
    "ws['I1'] = 'Penumonia ACC'\n",
    "ws['J1'] = 'Penumonia Recall'\n",
    "ws['K1'] = 'Penumonia Precision'\n",
    "ws['L1'] = 'Penumonia F1'\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    best_false_acc = 0.0\n",
    "    best_false_f1 = 0.0\n",
    "    best_pneumonia_acc = 0.0\n",
    "    best_pneumonia_f1 = 0.0\n",
    "\n",
    "    best_false_acc_epoch = 0\n",
    "    best_false_f1_epoch = 0\n",
    "    best_pneumonia_acc_epoch = 0\n",
    "    best_pneumonia_f1_epoch = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        val_false_TP = 0.0\n",
    "        val_pneumonia_TP = 0.0\n",
    "        val_false_FN = 0.0\n",
    "        val_pneumonia_FN = 0.0\n",
    "        val_false_TN = 0.0\n",
    "        val_pneumonia_TN = 0.0\n",
    "        val_false_FP = 0.0\n",
    "        val_pneumonia_FP = 0.0\n",
    "\n",
    "        \n",
    "        \n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        A = 'A'+str(epoch+2)\n",
    "        ws[A] = 'Epoch' + str(epoch+1)\n",
    "    \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    #outputs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    # Append batch prediction results\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                a = preds.size()\n",
    "                b = a[0]\n",
    "                \n",
    "                if phase == 'val':\n",
    "                    for i in range(b):\n",
    "                        if preds[i].item() == labels.data[i].item():\n",
    "                            #Normal-index:0, Pneumonia-index:1\n",
    "                            if preds.data[i].item() == 0: \n",
    "                                val_false_TP += 1 #Normal 관점에서는 normal를 정확히 분류하는 것이 TP\n",
    "                                val_pneumonia_TN += 1 #Pneumonia 관점에서는 normal를 정확히 분류하는 것이 TN\n",
    "                            elif preds.data[i].item() == 1: \n",
    "                                val_pneumonia_TP += 1 #Pneumonia 관점에서는 Pneumonia를 정확히 분류하는 것이 TP\n",
    "                                val_false_TN += 1 #Normal 관점에서는 Pneumonia를 정확히 분류하는 것이 TN\n",
    "\n",
    "                        if preds[i].item() != labels.data[i].item():\n",
    "                            if preds.data[i].item() == 0:\n",
    "                                val_false_FP += 1 #Normal 관점에서 normal라고 분류했지만 실제로는 pneumonia인 경우는 FP\n",
    "                                val_pneumonia_FN += 1 #Pneumonia 관점에서 normal라고 분류했지만 실제로는 pneumonia인 경우는 FN\n",
    "                            elif preds.data[i].item() == 1:\n",
    "                                val_pneumonia_FP += 1 #Normal 관점에서 pneumonia라고 분류했지만 실제로는 normal인 경우는 FP\n",
    "                                val_false_FN += 1 #Pneumonia 관점에서 pneumonia라고 분류했지만 실제로는 normal인 경우는 FN\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                \n",
    "            \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "           \n",
    "            if phase == 'val':\n",
    "                B = 'B'+str(epoch+2)\n",
    "                ws[B] = '{:.4f}'.format(epoch_acc*100)\n",
    "\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, (epoch_acc*100)))    \n",
    "\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "#                 best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "\n",
    "        #recall, precision -> https://en.wikipedia.org/wiki/Precision_and_recall\n",
    "        #recall = TP/(TP+FN)\n",
    "        #precision = TP/(TP+FP)\n",
    "        #ACC = (TP+TN)/(TP+TN+FP+FN)\n",
    "        false_recall = round(val_false_TP/(val_false_TP + val_false_FN),4)*100\n",
    "        pneumonia_recall = round(val_pneumonia_TP/(val_pneumonia_TP + val_pneumonia_FN),4)*100\n",
    "        false_precision = round(val_false_TP/(val_false_TP + val_false_FP),4)*100\n",
    "        pneumonia_precision = round(val_pneumonia_TP/(val_pneumonia_TP + val_pneumonia_FP),4)*100\n",
    "        false_acc = round((val_false_TP + val_false_TN)/(val_false_TP + val_false_FP +val_false_TN + val_false_FN),4)*100\n",
    "        pneumonia_acc = round((val_pneumonia_TP + val_pneumonia_TN)/(val_pneumonia_TP + val_pneumonia_FP +val_pneumonia_TN + val_pneumonia_FN),4)*100\n",
    "        #F1 score -> https://en.wikipedia.org/wiki/F-score\n",
    "        #F1 score = 2/((1/recall)+(1/precision)) = 2((precision*recall)/(precision+recall)) = tp/(tp+((1/2)(fp+fn)))\n",
    "        false_f1_score = round(2*(false_precision*false_recall)/(false_precision+false_recall),2)\n",
    "        pneumonia_f1_score = round(2*(pneumonia_precision*pneumonia_recall)/(pneumonia_precision+pneumonia_recall),2)\n",
    "\n",
    "        #total_data = batch size --> covid_total_dataset = false_total_dataset\n",
    "        false_total_dataset = int(val_false_TP + val_false_FP +val_false_TN + val_false_FN)\n",
    "        pneumonia_total_dataset = int(val_pneumonia_TP + val_pneumonia_FP +val_pneumonia_TN + val_pneumonia_FN)\n",
    "        \n",
    "      \n",
    "        D = 'D'+str(epoch+2)\n",
    "        E = 'E'+str(epoch+2)\n",
    "        F = 'F'+str(epoch+2)\n",
    "        G = 'G'+str(epoch+2)\n",
    "        \n",
    "        I = 'I'+str(epoch+2)\n",
    "        J = 'J'+str(epoch+2)\n",
    "        K = 'K'+str(epoch+2)\n",
    "        L = 'L'+str(epoch+2)\n",
    "\n",
    "        ws[D] = false_acc\n",
    "        ws[E] = false_recall\n",
    "        ws[F] = false_precision\n",
    "        ws[G] = false_f1_score\n",
    "        \n",
    "        ws[I] = pneumonia_acc\n",
    "        ws[J] = pneumonia_recall\n",
    "        ws[K] = pneumonia_precision\n",
    "        ws[L] = pneumonia_f1_score\n",
    "\n",
    "\n",
    "        print()\n",
    "\n",
    "        print('데이터셋A: ' + str(false_total_dataset))\n",
    "        print('False Recall: ' + str(false_recall))        \n",
    "        print('False Precision: ' + str(false_precision))\n",
    "        print('False ACC: ' + str(false_acc))\n",
    "        print('False F1 score: ' + str(false_f1_score))\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        print('데이터셋B: ' + str(pneumonia_total_dataset))\n",
    "        print('Pneumonia Recall: ' + str(pneumonia_recall))\n",
    "        print('Pneumonia Precision: ' + str(pneumonia_precision))\n",
    "        print('Pneumonia ACC: ' + str(pneumonia_acc))\n",
    "        print('Pneumonia F1 score: ' + str(pneumonia_f1_score))\n",
    "        \n",
    "  \n",
    "        if phase == 'val' and false_acc > best_false_acc:\n",
    "            best_false_acc = false_acc\n",
    "            best_false_acc_epoch = epoch\n",
    "\n",
    "        if phase == 'val' and pneumonia_acc > best_pneumonia_acc:\n",
    "            best_pneumonia_acc = pneumonia_acc\n",
    "            best_pneumonia_acc_epoch = epoch\n",
    "            \n",
    "\n",
    "        if phase == 'val' and false_f1_score > best_false_f1:\n",
    "            best_false_f1 = false_f1_score\n",
    "            best_false_f1_epoch = epoch\n",
    "            \n",
    "        if phase == 'val' and pneumonia_f1_score > best_pneumonia_f1:\n",
    "            best_pneumonia_f1 = pneumonia_f1_score\n",
    "            best_pneumonia_f1_epoch = epoch\n",
    "#             best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "        print()\n",
    "\n",
    "    \n",
    "    ws['N1'] = 'Best False ACC'\n",
    "    ws['O1'] = 'epoch'\n",
    "    ws['N2'] = round(best_false_acc,2)\n",
    "    ws['O2'] = best_false_acc_epoch+1\n",
    "        \n",
    "    ws['N4'] = 'Best False F1'\n",
    "    ws['O4'] = 'epoch'\n",
    "    ws['N5'] = round(best_false_f1,2)\n",
    "    ws['O5'] = best_false_f1_epoch+1\n",
    "        \n",
    "    ws['N7'] = 'Best Pneumonia ACC'\n",
    "    ws['O7'] = 'epoch'\n",
    "    ws['N8'] = round(best_pneumonia_acc,2)\n",
    "    ws['O8'] = best_pneumonia_acc_epoch+1\n",
    "        \n",
    "    ws['N10'] = 'Best Pneumonia F1'\n",
    "    ws['O10'] = 'epoch'\n",
    "    ws['N11'] = round(best_pneumonia_f1,2)\n",
    "    ws['O11'] = best_pneumonia_f1_epoch+1\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    #print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "    # load best model weights\n",
    "    #model.load_state_dict(best_covid_wts)\n",
    "    wb.save('output_excel/현수님세팅_Pneumonia_vs_Fasle(train5475_P 기준세팅)_Balanced(val)_seed_1_Mistake_layer_4_bottleneck_0.xlsx') # 엑셀로 저장한다. \n",
    "    #torch.save(model.state_dict(), 'covid_binary.pt')\n",
    "    return model\n",
    "\n",
    "\n",
    "model_ft = models.resnet50(pretrained=True)\n",
    "\n",
    "\n",
    "###BatchNorm Gamma setting###\n",
    "\n",
    "count =0\n",
    "layer_index=4\n",
    "layer_name = 'layer'+str(layer_index)\n",
    "\n",
    "for name, layer in model_ft.named_children():\n",
    "    if name == layer_name:\n",
    "        bottleneck_index = 0\n",
    "        bn_index = 1\n",
    "        for name, param in model_ft.named_parameters():\n",
    "            if name == layer_name + '.' + str(bottleneck_index) + '.' + 'bn1.weight':\n",
    "                print(str(layer_name + \"의 \" + str(bottleneck_index)+ \"번째-bottleneck의 \" + 'bn1.weight'))\n",
    "                torch.nn.init.ones_(param)\n",
    "                print(name + '의 gammm one setting 완료')\n",
    "                print()\n",
    "                \n",
    "            elif name == layer_name + '.' + str(bottleneck_index) + '.' + 'bn2.weight':\n",
    "                print(str(layer_name + \"의 \" + str(bottleneck_index)+ \"번째-bottleneck의 \" + 'bn2.weight'))\n",
    "                torch.nn.init.ones_(param)\n",
    "                print(name + '의 gammm one setting 완료')\n",
    "                print()\n",
    "\n",
    "            elif name == layer_name + '.' + str(bottleneck_index) + '.' + 'bn3.weight':\n",
    "                print(str(layer_name + \"의 \" + str(bottleneck_index)+ \"번째-bottleneck의 \" + 'bn3.weight'))\n",
    "                torch.nn.init.ones_(param)\n",
    "                print(name + '의 gammm zero setting 완료')\n",
    "                print()\n",
    "\n",
    "            elif name == layer_name + '.' + str(bottleneck_index) + '.' + 'bn' + str(bn_index) + '.bias':\n",
    "                print(str(layer_name + \"의 \" + str(bottleneck_index)+ \"번째-bottleneck의 \" + 'bn' + str(bn_index) + '.bias'))\n",
    "                torch.nn.init.zeros_(param)\n",
    "                bn_index = bn_index + 1\n",
    "                print(name + '의 beta zero setting 완료')\n",
    "                print()\n",
    "\n",
    "\n",
    "\n",
    "        bottleneck_index = bottleneck_index + 1\n",
    "\n",
    "        layer_index = layer_index+ 1\n",
    "        layer_name = 'layer'+str(layer_index)     \n",
    "\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)\n",
    "#exp_lr_scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max, eta_min=0, last_epoch=-1, verbose=False)\n",
    "exp_lr_scheduler = GradualWarmupScheduler(optimizer_ft, multiplier=1, total_epoch=5, after_scheduler=exp_lr_scheduler)\n",
    "#exp_lr_scheduler = cosine_annearing_with_warmup.CosineAnnealingWarmUpRestarts(optimizer_ft, T_0=30, T_mult=1, eta_max=0.001, T_up=20)\n",
    "\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=20)\n",
    "\n",
    "# freeze backbone layers\n",
    "'''\n",
    "count = 0\n",
    "for child_name, param in model_ft.named_children():\n",
    "    for param_name, param_param in model_ft.named_parameters():\n",
    "        if child_name == 'layer4': \n",
    "            param_param.requires_grad = True\n",
    "        else:\n",
    "            param_param.requires_grad = False\n",
    "'''\n",
    "\n",
    "\n",
    "#특정 conv layer 이후 초기화\n",
    "'''\n",
    "children_index = 4\n",
    "children_name = 'layer'+str(children_index)\n",
    "bottleneck_index = 2\n",
    "for name, layer in model_ft.named_children():\n",
    "    if name == children_name:\n",
    "        conv_index = 1\n",
    "        for name, param in model_ft.named_parameters():\n",
    "            if name == children_name + \".\" + str(bottleneck_index) + '.' + 'conv' + str(conv_index) + '.weight':\n",
    "                print(children_name + \"의 \"+ str(bottleneck_index)+ \"번째-bottleneck의 \" + 'conv' +str(conv_index) + '.weight')\n",
    "                torch.nn.init.xavier_uniform_(param)\n",
    "                print(name + '의 conv filter initilization setting 완료')\n",
    "                print()\n",
    "                conv_index = conv_index + 1\n",
    "                if name == 'layer3.' + str(bottleneck_index) + '.' + 'conv3.weight':\n",
    "                    bottleneck_index = bottleneck_index + 1\n",
    "                    conv_index = 1\n",
    "                elif name == 'layer4.' + str(bottleneck_index) + '.' + 'conv3.weight':\n",
    "                    bottleneck_index = bottleneck_index + 1\n",
    "                    conv_index = 1\n",
    "        children_index = children_index + 1\n",
    "        children_name = 'layer'+str(children_index)\n",
    "        bottleneck_index = 0\n",
    "'''        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#increase fine-tune layer per epoch\n",
    "'''\n",
    "if epoch < 6:\n",
    "    # freeze backbone layers\n",
    "    for param in net.parameters():\n",
    "        count +=1\n",
    "        if count < 4: #freezing first 3 layers\n",
    "            param.requires_grad = False    \n",
    "        else:\n",
    "            for param in net.parameters():\n",
    "                aram.requires_grad = True\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seed 2 _  Mistake code _ layer 4 bottindex 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 10950\n",
      "Validation dataset size: 300\n",
      "['false', 'pneumonia']\n",
      "######### Validation Dataset #########\n",
      "false size: 200\n",
      "pneumonia size: 100\n",
      "layer4의 0번째-bottleneck의 bn1.weight\n",
      "layer4.0.bn1.weight의 gammm one setting 완료\n",
      "\n",
      "layer4의 0번째-bottleneck의 bn1.bias\n",
      "layer4.0.bn1.bias의 beta zero setting 완료\n",
      "\n",
      "layer4의 0번째-bottleneck의 bn2.weight\n",
      "layer4.0.bn2.weight의 gammm one setting 완료\n",
      "\n",
      "layer4의 0번째-bottleneck의 bn2.bias\n",
      "layer4.0.bn2.bias의 beta zero setting 완료\n",
      "\n",
      "layer4의 0번째-bottleneck의 bn3.weight\n",
      "layer4.0.bn3.weight의 gammm zero setting 완료\n",
      "\n",
      "layer4의 0번째-bottleneck의 bn3.bias\n",
      "layer4.0.bn3.bias의 beta zero setting 완료\n",
      "\n",
      "Epoch 0/19\n",
      "----------\n",
      "val Loss: 0.7479 Acc: 37.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 27.0\n",
      "False Precision: 56.25\n",
      "False ACC: 37.330000000000005\n",
      "False F1 score: 36.49\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 57.99999999999999\n",
      "Pneumonia Precision: 28.43\n",
      "Pneumonia ACC: 37.330000000000005\n",
      "Pneumonia F1 score: 38.16\n",
      "\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "val Loss: 0.3351 Acc: 84.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 81.0\n",
      "False Precision: 94.74000000000001\n",
      "False ACC: 84.33\n",
      "False F1 score: 87.33\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 91.0\n",
      "Pneumonia Precision: 70.54\n",
      "Pneumonia ACC: 84.33\n",
      "Pneumonia F1 score: 79.47\n",
      "\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "val Loss: 0.4543 Acc: 77.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 70.0\n",
      "False Precision: 95.24000000000001\n",
      "False ACC: 77.66999999999999\n",
      "False F1 score: 80.69\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 93.0\n",
      "Pneumonia Precision: 60.78\n",
      "Pneumonia ACC: 77.66999999999999\n",
      "Pneumonia F1 score: 73.51\n",
      "\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "val Loss: 0.2749 Acc: 88.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 88.5\n",
      "False Precision: 93.65\n",
      "False ACC: 88.33\n",
      "False F1 score: 91.0\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 88.0\n",
      "Pneumonia Precision: 79.28\n",
      "Pneumonia ACC: 88.33\n",
      "Pneumonia F1 score: 83.41\n",
      "\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "val Loss: 0.3190 Acc: 85.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 81.5\n",
      "False Precision: 96.45\n",
      "False ACC: 85.67\n",
      "False F1 score: 88.35\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 71.76\n",
      "Pneumonia ACC: 85.67\n",
      "Pneumonia F1 score: 81.39\n",
      "\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "val Loss: 0.1709 Acc: 94.0000\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 96.0\n",
      "False Precision: 95.05\n",
      "False ACC: 94.0\n",
      "False F1 score: 95.52\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 90.0\n",
      "Pneumonia Precision: 91.84\n",
      "Pneumonia ACC: 94.0\n",
      "Pneumonia F1 score: 90.91\n",
      "\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "val Loss: 0.1284 Acc: 95.0000\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 95.5\n",
      "False Precision: 96.95\n",
      "False ACC: 95.0\n",
      "False F1 score: 96.22\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 91.25999999999999\n",
      "Pneumonia ACC: 95.0\n",
      "Pneumonia F1 score: 92.61\n",
      "\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "val Loss: 0.3144 Acc: 86.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 82.5\n",
      "False Precision: 96.49\n",
      "False ACC: 86.33\n",
      "False F1 score: 88.95\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 72.87\n",
      "Pneumonia ACC: 86.33\n",
      "Pneumonia F1 score: 82.1\n",
      "\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "val Loss: 0.1849 Acc: 96.0000\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 97.5\n",
      "False Precision: 96.53\n",
      "False ACC: 96.0\n",
      "False F1 score: 97.01\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 93.0\n",
      "Pneumonia Precision: 94.89999999999999\n",
      "Pneumonia ACC: 96.0\n",
      "Pneumonia F1 score: 93.94\n",
      "\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "val Loss: 0.2213 Acc: 92.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 91.5\n",
      "False Precision: 96.83\n",
      "False ACC: 92.33\n",
      "False F1 score: 94.09\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 84.68\n",
      "Pneumonia ACC: 92.33\n",
      "Pneumonia F1 score: 89.1\n",
      "\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "val Loss: 0.1906 Acc: 94.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 95.0\n",
      "False Precision: 96.45\n",
      "False ACC: 94.33\n",
      "False F1 score: 95.72\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 93.0\n",
      "Pneumonia Precision: 90.29\n",
      "Pneumonia ACC: 94.33\n",
      "Pneumonia F1 score: 91.62\n",
      "\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "val Loss: 0.2019 Acc: 93.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 93.5\n",
      "False Precision: 96.89\n",
      "False ACC: 93.67\n",
      "False F1 score: 95.16\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 87.85\n",
      "Pneumonia ACC: 93.67\n",
      "Pneumonia F1 score: 90.82\n",
      "\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "val Loss: 0.2043 Acc: 93.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 93.5\n",
      "False Precision: 96.39\n",
      "False ACC: 93.33\n",
      "False F1 score: 94.92\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 93.0\n",
      "Pneumonia Precision: 87.74\n",
      "Pneumonia ACC: 93.33\n",
      "Pneumonia F1 score: 90.29\n",
      "\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "val Loss: 0.1844 Acc: 94.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 95.0\n",
      "False Precision: 96.45\n",
      "False ACC: 94.33\n",
      "False F1 score: 95.72\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 93.0\n",
      "Pneumonia Precision: 90.29\n",
      "Pneumonia ACC: 94.33\n",
      "Pneumonia F1 score: 91.62\n",
      "\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "val Loss: 0.2586 Acc: 91.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 90.5\n",
      "False Precision: 96.78999999999999\n",
      "False ACC: 91.67\n",
      "False F1 score: 93.54\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 83.19\n",
      "Pneumonia ACC: 91.67\n",
      "Pneumonia F1 score: 88.27\n",
      "\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "val Loss: 0.2256 Acc: 93.0000\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 92.5\n",
      "False Precision: 96.86\n",
      "False ACC: 93.0\n",
      "False F1 score: 94.63\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 86.24000000000001\n",
      "Pneumonia ACC: 93.0\n",
      "Pneumonia F1 score: 89.95\n",
      "\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "val Loss: 0.2401 Acc: 92.0000\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 91.0\n",
      "False Precision: 96.81\n",
      "False ACC: 92.0\n",
      "False F1 score: 93.82\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 94.0\n",
      "Pneumonia Precision: 83.93\n",
      "Pneumonia ACC: 92.0\n",
      "Pneumonia F1 score: 88.68\n",
      "\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "val Loss: 0.2054 Acc: 93.0000\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 93.0\n",
      "False Precision: 96.37\n",
      "False ACC: 93.0\n",
      "False F1 score: 94.66\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 93.0\n",
      "Pneumonia Precision: 86.92\n",
      "Pneumonia ACC: 93.0\n",
      "Pneumonia F1 score: 89.86\n",
      "\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "val Loss: 0.2004 Acc: 93.6667\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 94.0\n",
      "False Precision: 96.41\n",
      "False ACC: 93.67\n",
      "False F1 score: 95.19\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 93.0\n",
      "Pneumonia Precision: 88.57000000000001\n",
      "Pneumonia ACC: 93.67\n",
      "Pneumonia F1 score: 90.73\n",
      "\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "val Loss: 0.2053 Acc: 93.3333\n",
      "\n",
      "데이터셋A: 300\n",
      "False Recall: 93.5\n",
      "False Precision: 96.39\n",
      "False ACC: 93.33\n",
      "False F1 score: 94.92\n",
      "\n",
      "데이터셋B: 300\n",
      "Pneumonia Recall: 93.0\n",
      "Pneumonia Precision: 87.74\n",
      "Pneumonia ACC: 93.33\n",
      "Pneumonia F1 score: 90.29\n",
      "\n",
      "\n",
      "Training complete in 33m 29s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nif epoch < 6:\\n    # freeze backbone layers\\n    for param in net.parameters():\\n        count +=1\\n        if count < 4: #freezing first 3 layers\\n            param.requires_grad = False    \\n        else:\\n            for param in net.parameters():\\n                aram.requires_grad = True\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Author: Sasank Chilamkurthy\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "from openpyxl import Workbook\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "# from pytorch_cosine_annealing_warmup_master import cosine_annearing_with_warmup\n",
    "import random\n",
    "\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "#torch.set_deterministic(True)\n",
    "random_seed = 2\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.3)),\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.15,0.1)),\n",
    "        transforms.RandomAffine(degrees=(-10,10)),\n",
    "        transforms.Resize(280),\n",
    "        transforms.CenterCrop(224),\n",
    "        #transforms.Resize(size=(224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        transforms.Normalize([0.493, 0.493, 0.493], [0.246, 0.246, 0.246])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        #transforms.Resize(size=(224,224)),\n",
    "        transforms.Resize(280),\n",
    "        transforms.CenterCrop(224),\n",
    "        #transforms.Resize(size=(224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        transforms.Normalize([0.493, 0.493, 0.493], [0.246, 0.246, 0.246])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = '/home/aiffel/Hackathon_covid_19/data_2'\n",
    "#data_dir = 'Crop_CXR/binary_covid'\n",
    "batch_size = 16\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "val_class_names = image_datasets['val'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Training dataset size: \" + str(dataset_sizes['train']))\n",
    "print(\"Validation dataset size: \" +str(dataset_sizes['val']))\n",
    "print(val_class_names)\n",
    "\n",
    "\n",
    "val_dir = '/home/aiffel/Hackathon_covid_19/data_2/val/'\n",
    "false_data_dir = val_dir + 'false'\n",
    "pneumonia_data_dir = val_dir + 'pneumonia'\n",
    "\n",
    "print(\"######### Validation Dataset #########\")\n",
    "val_false_num = len(os.listdir(false_data_dir))\n",
    "val_pneumonia_num = len(os.listdir(pneumonia_data_dir))\n",
    "print(\"false size: \" + str(val_false_num))\n",
    "print(\"pneumonia size: \" + str(val_pneumonia_num))\n",
    "\n",
    "wb = Workbook()      # 워크북을 생성한다.\n",
    "ws = wb.active       # 워크 시트를 얻는다.\n",
    "    \n",
    "ws['A1'] = 'ResNet50'\n",
    "ws['B1'] = 'Val ACC'\n",
    "\n",
    "ws['D1'] = 'False ACC'\n",
    "ws['E1'] = 'False Recall'\n",
    "ws['F1'] = 'False Precision'\n",
    "ws['G1'] = 'False F1'\n",
    "\n",
    "ws['I1'] = 'Penumonia ACC'\n",
    "ws['J1'] = 'Penumonia Recall'\n",
    "ws['K1'] = 'Penumonia Precision'\n",
    "ws['L1'] = 'Penumonia F1'\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    best_false_acc = 0.0\n",
    "    best_false_f1 = 0.0\n",
    "    best_pneumonia_acc = 0.0\n",
    "    best_pneumonia_f1 = 0.0\n",
    "\n",
    "    best_false_acc_epoch = 0\n",
    "    best_false_f1_epoch = 0\n",
    "    best_pneumonia_acc_epoch = 0\n",
    "    best_pneumonia_f1_epoch = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        val_false_TP = 0.0\n",
    "        val_pneumonia_TP = 0.0\n",
    "        val_false_FN = 0.0\n",
    "        val_pneumonia_FN = 0.0\n",
    "        val_false_TN = 0.0\n",
    "        val_pneumonia_TN = 0.0\n",
    "        val_false_FP = 0.0\n",
    "        val_pneumonia_FP = 0.0\n",
    "\n",
    "        \n",
    "        \n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        A = 'A'+str(epoch+2)\n",
    "        ws[A] = 'Epoch' + str(epoch+1)\n",
    "    \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    #outputs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    # Append batch prediction results\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                a = preds.size()\n",
    "                b = a[0]\n",
    "                \n",
    "                if phase == 'val':\n",
    "                    for i in range(b):\n",
    "                        if preds[i].item() == labels.data[i].item():\n",
    "                            #Normal-index:0, Pneumonia-index:1\n",
    "                            if preds.data[i].item() == 0: \n",
    "                                val_false_TP += 1 #Normal 관점에서는 normal를 정확히 분류하는 것이 TP\n",
    "                                val_pneumonia_TN += 1 #Pneumonia 관점에서는 normal를 정확히 분류하는 것이 TN\n",
    "                            elif preds.data[i].item() == 1: \n",
    "                                val_pneumonia_TP += 1 #Pneumonia 관점에서는 Pneumonia를 정확히 분류하는 것이 TP\n",
    "                                val_false_TN += 1 #Normal 관점에서는 Pneumonia를 정확히 분류하는 것이 TN\n",
    "\n",
    "                        if preds[i].item() != labels.data[i].item():\n",
    "                            if preds.data[i].item() == 0:\n",
    "                                val_false_FP += 1 #Normal 관점에서 normal라고 분류했지만 실제로는 pneumonia인 경우는 FP\n",
    "                                val_pneumonia_FN += 1 #Pneumonia 관점에서 normal라고 분류했지만 실제로는 pneumonia인 경우는 FN\n",
    "                            elif preds.data[i].item() == 1:\n",
    "                                val_pneumonia_FP += 1 #Normal 관점에서 pneumonia라고 분류했지만 실제로는 normal인 경우는 FP\n",
    "                                val_false_FN += 1 #Pneumonia 관점에서 pneumonia라고 분류했지만 실제로는 normal인 경우는 FN\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                \n",
    "            \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "           \n",
    "            if phase == 'val':\n",
    "                B = 'B'+str(epoch+2)\n",
    "                ws[B] = '{:.4f}'.format(epoch_acc*100)\n",
    "\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, (epoch_acc*100)))    \n",
    "\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "#                 best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "\n",
    "        #recall, precision -> https://en.wikipedia.org/wiki/Precision_and_recall\n",
    "        #recall = TP/(TP+FN)\n",
    "        #precision = TP/(TP+FP)\n",
    "        #ACC = (TP+TN)/(TP+TN+FP+FN)\n",
    "        false_recall = round(val_false_TP/(val_false_TP + val_false_FN),4)*100\n",
    "        pneumonia_recall = round(val_pneumonia_TP/(val_pneumonia_TP + val_pneumonia_FN),4)*100\n",
    "        false_precision = round(val_false_TP/(val_false_TP + val_false_FP),4)*100\n",
    "        pneumonia_precision = round(val_pneumonia_TP/(val_pneumonia_TP + val_pneumonia_FP),4)*100\n",
    "        false_acc = round((val_false_TP + val_false_TN)/(val_false_TP + val_false_FP +val_false_TN + val_false_FN),4)*100\n",
    "        pneumonia_acc = round((val_pneumonia_TP + val_pneumonia_TN)/(val_pneumonia_TP + val_pneumonia_FP +val_pneumonia_TN + val_pneumonia_FN),4)*100\n",
    "        #F1 score -> https://en.wikipedia.org/wiki/F-score\n",
    "        #F1 score = 2/((1/recall)+(1/precision)) = 2((precision*recall)/(precision+recall)) = tp/(tp+((1/2)(fp+fn)))\n",
    "        false_f1_score = round(2*(false_precision*false_recall)/(false_precision+false_recall),2)\n",
    "        pneumonia_f1_score = round(2*(pneumonia_precision*pneumonia_recall)/(pneumonia_precision+pneumonia_recall),2)\n",
    "\n",
    "        #total_data = batch size --> covid_total_dataset = false_total_dataset\n",
    "        false_total_dataset = int(val_false_TP + val_false_FP +val_false_TN + val_false_FN)\n",
    "        pneumonia_total_dataset = int(val_pneumonia_TP + val_pneumonia_FP +val_pneumonia_TN + val_pneumonia_FN)\n",
    "        \n",
    "      \n",
    "        D = 'D'+str(epoch+2)\n",
    "        E = 'E'+str(epoch+2)\n",
    "        F = 'F'+str(epoch+2)\n",
    "        G = 'G'+str(epoch+2)\n",
    "        \n",
    "        I = 'I'+str(epoch+2)\n",
    "        J = 'J'+str(epoch+2)\n",
    "        K = 'K'+str(epoch+2)\n",
    "        L = 'L'+str(epoch+2)\n",
    "\n",
    "        ws[D] = false_acc\n",
    "        ws[E] = false_recall\n",
    "        ws[F] = false_precision\n",
    "        ws[G] = false_f1_score\n",
    "        \n",
    "        ws[I] = pneumonia_acc\n",
    "        ws[J] = pneumonia_recall\n",
    "        ws[K] = pneumonia_precision\n",
    "        ws[L] = pneumonia_f1_score\n",
    "\n",
    "\n",
    "        print()\n",
    "\n",
    "        print('데이터셋A: ' + str(false_total_dataset))\n",
    "        print('False Recall: ' + str(false_recall))        \n",
    "        print('False Precision: ' + str(false_precision))\n",
    "        print('False ACC: ' + str(false_acc))\n",
    "        print('False F1 score: ' + str(false_f1_score))\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        print('데이터셋B: ' + str(pneumonia_total_dataset))\n",
    "        print('Pneumonia Recall: ' + str(pneumonia_recall))\n",
    "        print('Pneumonia Precision: ' + str(pneumonia_precision))\n",
    "        print('Pneumonia ACC: ' + str(pneumonia_acc))\n",
    "        print('Pneumonia F1 score: ' + str(pneumonia_f1_score))\n",
    "        \n",
    "  \n",
    "        if phase == 'val' and false_acc > best_false_acc:\n",
    "            best_false_acc = false_acc\n",
    "            best_false_acc_epoch = epoch\n",
    "\n",
    "        if phase == 'val' and pneumonia_acc > best_pneumonia_acc:\n",
    "            best_pneumonia_acc = pneumonia_acc\n",
    "            best_pneumonia_acc_epoch = epoch\n",
    "            \n",
    "\n",
    "        if phase == 'val' and false_f1_score > best_false_f1:\n",
    "            best_false_f1 = false_f1_score\n",
    "            best_false_f1_epoch = epoch\n",
    "            \n",
    "        if phase == 'val' and pneumonia_f1_score > best_pneumonia_f1:\n",
    "            best_pneumonia_f1 = pneumonia_f1_score\n",
    "            best_pneumonia_f1_epoch = epoch\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "        print()\n",
    "\n",
    "    \n",
    "    ws['N1'] = 'Best False ACC'\n",
    "    ws['O1'] = 'epoch'\n",
    "    ws['N2'] = round(best_false_acc,2)\n",
    "    ws['O2'] = best_false_acc_epoch+1\n",
    "        \n",
    "    ws['N4'] = 'Best False F1'\n",
    "    ws['O4'] = 'epoch'\n",
    "    ws['N5'] = round(best_false_f1,2)\n",
    "    ws['O5'] = best_false_f1_epoch+1\n",
    "        \n",
    "    ws['N7'] = 'Best Pneumonia ACC'\n",
    "    ws['O7'] = 'epoch'\n",
    "    ws['N8'] = round(best_pneumonia_acc,2)\n",
    "    ws['O8'] = best_pneumonia_acc_epoch+1\n",
    "        \n",
    "    ws['N10'] = 'Best Pneumonia F1'\n",
    "    ws['O10'] = 'epoch'\n",
    "    ws['N11'] = round(best_pneumonia_f1,2)\n",
    "    ws['O11'] = best_pneumonia_f1_epoch+1\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    #print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "    # load best model weights\n",
    "    #model.load_state_dict(best_covid_wts)\n",
    "#     wb.save('output_excel/현수님세팅_Pneumonia_vs_Fasle(train5475_P 기준세팅)_Balanced(val)_seed_2_Mistake_layer_4_bottleneck_0.xlsx') # 엑셀로 저장한다. \n",
    "    torch.save(model.state_dict(), 'Final_Pneumonia_binary.pt')\n",
    "    return model\n",
    "\n",
    "\n",
    "model_ft = models.resnet50(pretrained=True)\n",
    "\n",
    "\n",
    "###BatchNorm Gamma setting###\n",
    "\n",
    "count =0\n",
    "layer_index=4\n",
    "layer_name = 'layer'+str(layer_index)\n",
    "\n",
    "for name, layer in model_ft.named_children():\n",
    "    if name == layer_name:\n",
    "        bottleneck_index = 0\n",
    "        bn_index = 1\n",
    "        for name, param in model_ft.named_parameters():\n",
    "            if name == layer_name + '.' + str(bottleneck_index) + '.' + 'bn1.weight':\n",
    "                print(str(layer_name + \"의 \" + str(bottleneck_index)+ \"번째-bottleneck의 \" + 'bn1.weight'))\n",
    "                torch.nn.init.ones_(param)\n",
    "                print(name + '의 gammm one setting 완료')\n",
    "                print()\n",
    "                \n",
    "            elif name == layer_name + '.' + str(bottleneck_index) + '.' + 'bn2.weight':\n",
    "                print(str(layer_name + \"의 \" + str(bottleneck_index)+ \"번째-bottleneck의 \" + 'bn2.weight'))\n",
    "                torch.nn.init.ones_(param)\n",
    "                print(name + '의 gammm one setting 완료')\n",
    "                print()\n",
    "\n",
    "            elif name == layer_name + '.' + str(bottleneck_index) + '.' + 'bn3.weight':\n",
    "                print(str(layer_name + \"의 \" + str(bottleneck_index)+ \"번째-bottleneck의 \" + 'bn3.weight'))\n",
    "                torch.nn.init.ones_(param)\n",
    "                print(name + '의 gammm zero setting 완료')\n",
    "                print()\n",
    "\n",
    "            elif name == layer_name + '.' + str(bottleneck_index) + '.' + 'bn' + str(bn_index) + '.bias':\n",
    "                print(str(layer_name + \"의 \" + str(bottleneck_index)+ \"번째-bottleneck의 \" + 'bn' + str(bn_index) + '.bias'))\n",
    "                torch.nn.init.zeros_(param)\n",
    "                bn_index = bn_index + 1\n",
    "                print(name + '의 beta zero setting 완료')\n",
    "                print()\n",
    "\n",
    "\n",
    "\n",
    "        bottleneck_index = bottleneck_index + 1\n",
    "\n",
    "        layer_index = layer_index+ 1\n",
    "        layer_name = 'layer'+str(layer_index)     \n",
    "\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)\n",
    "#exp_lr_scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max, eta_min=0, last_epoch=-1, verbose=False)\n",
    "exp_lr_scheduler = GradualWarmupScheduler(optimizer_ft, multiplier=1, total_epoch=5, after_scheduler=exp_lr_scheduler)\n",
    "#exp_lr_scheduler = cosine_annearing_with_warmup.CosineAnnealingWarmUpRestarts(optimizer_ft, T_0=30, T_mult=1, eta_max=0.001, T_up=20)\n",
    "\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=20)\n",
    "\n",
    "# freeze backbone layers\n",
    "'''\n",
    "count = 0\n",
    "for child_name, param in model_ft.named_children():\n",
    "    for param_name, param_param in model_ft.named_parameters():\n",
    "        if child_name == 'layer4': \n",
    "            param_param.requires_grad = True\n",
    "        else:\n",
    "            param_param.requires_grad = False\n",
    "'''\n",
    "\n",
    "\n",
    "#특정 conv layer 이후 초기화\n",
    "'''\n",
    "children_index = 4\n",
    "children_name = 'layer'+str(children_index)\n",
    "bottleneck_index = 2\n",
    "for name, layer in model_ft.named_children():\n",
    "    if name == children_name:\n",
    "        conv_index = 1\n",
    "        for name, param in model_ft.named_parameters():\n",
    "            if name == children_name + \".\" + str(bottleneck_index) + '.' + 'conv' + str(conv_index) + '.weight':\n",
    "                print(children_name + \"의 \"+ str(bottleneck_index)+ \"번째-bottleneck의 \" + 'conv' +str(conv_index) + '.weight')\n",
    "                torch.nn.init.xavier_uniform_(param)\n",
    "                print(name + '의 conv filter initilization setting 완료')\n",
    "                print()\n",
    "                conv_index = conv_index + 1\n",
    "                if name == 'layer3.' + str(bottleneck_index) + '.' + 'conv3.weight':\n",
    "                    bottleneck_index = bottleneck_index + 1\n",
    "                    conv_index = 1\n",
    "                elif name == 'layer4.' + str(bottleneck_index) + '.' + 'conv3.weight':\n",
    "                    bottleneck_index = bottleneck_index + 1\n",
    "                    conv_index = 1\n",
    "        children_index = children_index + 1\n",
    "        children_name = 'layer'+str(children_index)\n",
    "        bottleneck_index = 0\n",
    "'''        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#increase fine-tune layer per epoch\n",
    "'''\n",
    "if epoch < 6:\n",
    "    # freeze backbone layers\n",
    "    for param in net.parameters():\n",
    "        count +=1\n",
    "        if count < 4: #freezing first 3 layers\n",
    "            param.requires_grad = False    \n",
    "        else:\n",
    "            for param in net.parameters():\n",
    "                aram.requires_grad = True\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch virtual env",
   "language": "python",
   "name": "envtorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
